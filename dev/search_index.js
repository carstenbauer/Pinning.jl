var documenterSearchIndex = {"docs":
[{"location":"refs/internals/#Internals","page":"Internals","title":"Internals","text":"","category":"section"},{"location":"refs/internals/","page":"Internals","title":"Internals","text":"warning: Warning\nThis section isn't part of the official API. Things might change at any point without further notice.","category":"page"},{"location":"refs/internals/#Utility","page":"Internals","title":"Utility","text":"","category":"section"},{"location":"refs/internals/","page":"Internals","title":"Internals","text":"Modules = [ThreadPinning.Utility]\nPages   = [\"utility.jl\"]","category":"page"},{"location":"refs/internals/#ThreadPinning.Utility.BLAS_lib-Tuple{}","page":"Internals","title":"ThreadPinning.Utility.BLAS_lib","text":"Returns the name of the loaded BLAS library (the first, if multiple are loaded).\n\n\n\n\n\n","category":"method"},{"location":"refs/internals/#ThreadPinning.Utility._execute-Tuple{Cmd}","page":"Internals","title":"ThreadPinning.Utility._execute","text":"Run a Cmd object, returning the stdout & stderr contents plus the exit code\n\n\n\n\n\n","category":"method"},{"location":"refs/internals/#ThreadPinning.Utility.affinitymask2cpuids-Tuple{AbstractVector{<:Integer}}","page":"Internals","title":"ThreadPinning.Utility.affinitymask2cpuids","text":"Turn the affinity mask (a vector of ones and zeros) into a vector of CPU IDs.\n\n\n\n\n\n","category":"method"},{"location":"refs/internals/#ThreadPinning.Utility.cpuids2affinitymask-Tuple{AbstractVector{<:Integer}}","page":"Internals","title":"ThreadPinning.Utility.cpuids2affinitymask","text":"Turn the vector of CPU IDs into an affinity mask (a vector of ones and zeros).\n\n\n\n\n\n","category":"method"},{"location":"refs/internals/#ThreadPinning.Utility.nblasthreads-Tuple{}","page":"Internals","title":"ThreadPinning.Utility.nblasthreads","text":"Number of BLAS threads.\n\n\n\n\n\n","category":"method"},{"location":"refs/internals/#ThreadPinning.Utility.taskid-Tuple{}","page":"Internals","title":"ThreadPinning.Utility.taskid","text":"Returns a (most likely) unique id for the calling task.\n\n\n\n\n\n","category":"method"},{"location":"refs/internals/#MKL","page":"Internals","title":"MKL","text":"","category":"section"},{"location":"refs/internals/","page":"Internals","title":"Internals","text":"Modules = [ThreadPinning.MKL]\nPages   = [\"mkl.jl\"]","category":"page"},{"location":"refs/internals/#ThreadPinning.MKL.mkl_fullpath-Tuple{}","page":"Internals","title":"ThreadPinning.MKL.mkl_fullpath","text":"Returns the full path to the libmkl_rt library if the latter is loaded. Will try to locate the library and, if successfull, will cache the result. Throws an error otherwise.\n\nTo force an update of the cache, provide force_update=true.\n\n\n\n\n\n","category":"method"},{"location":"refs/internals/#ThreadPinning.MKL.mkl_get_dynamic-Tuple{}","page":"Internals","title":"ThreadPinning.MKL.mkl_get_dynamic","text":"mkl_get_dynamic()\n\nWrapper around the MKL function mkl_get_dynamic.\n\n\n\n\n\n","category":"method"},{"location":"refs/internals/#ThreadPinning.MKL.mkl_is_loaded-Tuple{}","page":"Internals","title":"ThreadPinning.MKL.mkl_is_loaded","text":"Check whether Intel MKL is currently loaded via libblastrampoline\n\n\n\n\n\n","category":"method"},{"location":"refs/internals/#ThreadPinning.MKL.mkl_set_dynamic-Tuple{Integer}","page":"Internals","title":"ThreadPinning.MKL.mkl_set_dynamic","text":"mkl_set_dynamic(flag::Integer)\n\nWrapper around the MKL function mkl_set_dynamic.\n\n\n\n\n\n","category":"method"},{"location":"examples/ex_affinity/#exaffinitymask","page":"External Affinity Mask","title":"External Affinity Mask","text":"","category":"section"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"In scenarios where the Julia process has a specific affinity mask, e.g. when running under taskset, numactl, or SLURM, you may want to pin your Julia threads in accordance with this affinity mask. To that end, we provide pinthreads(:affinitymask), which pins Julia threads to non-masked CPU-threads (in order, hyperthreads are only used if necessary).","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"For the demonstration below, we consider the following Julia script:","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"$ cat check.jl \nusing ThreadPinning\nif length(ARGS) > 0 && ARGS[1] == \"pin\"\n    pinthreads(:affinitymask)\nend\nprintln(getcpuids())\nprintln(\"no double occupancies: \", length(unique(getcpuids())) == length(getcpuids()))\nprintln(\"in order: \", issorted(getcpuids()))","category":"page"},{"location":"examples/ex_affinity/#tasksetheading","page":"External Affinity Mask","title":"taskset","text":"","category":"section"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"Let's use taskset --cpu-list to set the affinity of the Julia process.","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"$ taskset --cpu-list 0-24 julia --project -t 25 check.jl\n[13, 13, 4, 5, 6, 7, 8, 11, 15, 14, 12, 16, 18, 19, 0, 10, 3, 9, 24, 2, 17, 20, 1, 21, 21]\nno double occupancies: false\nin order: false","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"Note that","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"some Julia threads may run on the same CPU-thread(!) (which is almost certainly not desired), and\nthe order of the Julia thread to CPU-thread mapping is arbitrary (and non-deterministic).","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"We can remedy both points with pinthreads(:affinitymask):","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"$ taskset --cpu-list 0-24 julia --project -t 25 check.jl pin\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nno double occupancies: true\nin order: true","category":"page"},{"location":"examples/ex_affinity/#numactl","page":"External Affinity Mask","title":"numactl","text":"","category":"section"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"The same comments as made for taskset above also apply to numactl --physcpubind. Without pinthreads(:affinitymask):","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"$ numactl --physcpubind=0-24 julia --project -t 25 check.jl \n[6, 10, 7, 13, 14, 15, 8, 16, 19, 0, 5, 2, 3, 4, 18, 1, 9, 17, 20, 20, 12, 20, 10, 20, 11]\nno double occupancies: false\nin order: false","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"With pinthreads(:affinitymask):","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"$ numactl --physcpubind=0-24 julia --project -t 25 check.jl pin\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nno double occupancies: true\nin order: true","category":"page"},{"location":"examples/ex_affinity/#SLURM","page":"External Affinity Mask","title":"SLURM","text":"","category":"section"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"note: Note\nSLURM settings vary a lot between clusters, in particular affinity related settings. In the following, we visualize the affinity mask set by SLURM at the top of the output files (B means \"this CPU can be used\" whereas - indicates \"this CPU can't be used\" and vertical lines indicate different domains.). Be wary that the same job scripts might not set affinity masks on your cluster!","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"$ cat slurm_basic.jl \n#!/usr/bin/env sh\n#SBATCH -N 1\n#SBATCH -n 1\n#SBATCH --cpus-per-task 25\n#SBATCH -o sl_%j.out\n#SBATCH -A pc2-mitarbeiter\n#SBATCH -p all\n#SBATCH -t 00:02:00\n\nsrun -n 1 julia --project -t 25 check.jl ","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"Without pinthreads(:affinitymask):","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"$ cat sl_2374255.out \ncpu-bind=MASK - cn-0181, task  0  0 [1410285]: mask |BBBBBBBBBBBBBBBBBBBB||||BBBBB---------------|  set\ncpu-bind=MASK - cn-0181, task  0  0 [1410316]: mask |BBBBBBBBBBBBBBBBBBBB||||BBBBB---------------|  set\n[11, 16, 17, 2, 15, 18, 19, 13, 3, 4, 5, 6, 7, 10, 9, 8, 14, 11, 20, 0, 12, 13, 4, 2, 1]\nno double occupancies: false\nin order: false","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"Note that","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"some Julia threads may run on the same CPU-thread(!) (which is almost certainly not desired), and\nthe order of the Julia thread to CPU-thread mapping is arbitrary (and non-deterministic).","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"We can remedy both points with pinthreads(:affinitymask):","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"$ cat sl_2374256.out \ncpu-bind=MASK - cn-0197, task  0  0 [1507377]: mask |BBBBBBBBBBBBBBBBBBBB||||BBBBB---------------|  set\ncpu-bind=MASK - cn-0197, task  0  0 [1507410]: mask |BBBBBBBBBBBBBBBBBBBB||||BBBBB---------------|  set\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nno double occupancies: true\nin order: true","category":"page"},{"location":"examples/ex_affinity/#Supplement:-tauto-(Julia-1.9)","page":"External Affinity Mask","title":"Supplement: -tauto (Julia >= 1.9)","text":"","category":"section"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"For Julia >= 1.9 you can use -tauto to automatically set the number of Julia threads such that it matches the external affinity mask (relevant PR). This is particularly useful when using SLURM, but, for simplicity, we can also showcase it with taskset:","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"$ taskset --cpu-list 0-24 julia +1.9 -tauto --project check.jl pin\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nno double occupancies: true\nin order: true","category":"page"},{"location":"examples/ex_affinity/","page":"External Affinity Mask","title":"External Affinity Mask","text":"$ taskset --cpu-list 0-11 julia +1.9 -tauto --project check.jl pin\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\nno double occupancies: true\nin order: true","category":"page"},{"location":"examples/ex_pinning_julia_threads/#Pinning-Julia-Threads","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"The most important functions are pinthreads and threadinfo. The former allows you to pin threads. The latter visualizes the current thread-processor mapping and the system topology. Please check out the comprehensive documentation of these functions for detailed information. ","category":"page"},{"location":"examples/ex_pinning_julia_threads/#Typical-usage","page":"Pinning Julia Threads","title":"Typical usage","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/#pinthreads","page":"Pinning Julia Threads","title":"pinthreads","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Pinning your threads is as simple as putting the following at the top of your Julia code:","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"using ThreadPinning\npinthreads(:cores)","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"This will successively pin all Julia threads to CPU-cores in logical order, avoiding \"hyperthreads\" if possible. Of course, you can replace :cores by all the options supported by pinthreads. Conceptually, there are three different formats to specify your desired thread-processor mapping:","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"predefined symbols (e.g. :cores or :sockets),\nlogical specification of domains via helper functions (e.g. node and socket),\nexplicit lists of CPU IDs, e.g. 0:3 or [0,12,4] (as the OS defines them).","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"For example, instead of pinthreads(:cores) above, you could write pinthreads(:sockets), pinthreads(socket(1,1:3), numa(2,2:5)), or pinthreads(1:2:10). See pinthreads for more information.","category":"page"},{"location":"examples/ex_pinning_julia_threads/#threadinfo","page":"Pinning Julia Threads","title":"threadinfo","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"To check and visualize the current placement of threads you can use threadinfo.","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"(Image: threadinfo_unpinned.png)","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"As you can see, this image is taken on a dual-socket system where each CPU has 64 CPU-cores and Julia has been started with 5 threads. Hyperthreading is enabled with two CPU-threads per core (the greyed out numbers indicate hyperthreads/SMT-threads and the gap between numbers indicates different cores).","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Notably, the threads aren't pinned. Not only are they randomly placed on the system but two of them do even overlap in the sense that they are currently both running on the same CPU-thread, leading to contention.","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"If we pin threads to different cores (pinthreads(:cores)) and call threadinfo() again we obtain this:","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"(Image: threadinfo_pinned.png)","category":"page"},{"location":"examples/ex_pinning_julia_threads/#Keyword-options","page":"Pinning Julia Threads","title":"Keyword options","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Note that threadinfo has quite a number of keyword arguments that let you change or tune the output. The most important one is probably groupby. It allows you to switch from socket to, say, NUMA/memory domain visualization (groupby=:numa).","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"julia> pinthreads(:numa) # round-robin distribution among NUMA domains\n\njulia> threadinfo(; color=false, groupby=:numa) # grouping by NUMA domains (instead of CPU sockets)\nHostname: \tPerlmutterComputeNode\nCPU(s): \t2 x AMD EPYC 7763 64-Core Processor\nCPU target: \tznver3\nCores: \t\t128 (256 CPU-threads due to 2-way SMT)\nNUMA domains: \t8 (16 cores each)\n\nJulia threads: \t16\n\nNUMA domain 1\n  0,_, 1,_, _,_, _,_, _,_, _,_, _,_, _,_,\n  _,_, _,_, _,_, _,_, _,_, _,_, _,_, _,_\n\nNUMA domain 2\n  16,_, 17,_, _,_, _,_, _,_, _,_, _,_, _,_,\n  _,_, _,_, _,_, _,_, _,_, _,_, _,_, _,_\n\nNUMA domain 3\n  32,_, 33,_, _,_, _,_, _,_, _,_, _,_, _,_,\n  _,_, _,_, _,_, _,_, _,_, _,_, _,_, _,_\n\nNUMA domain 4\n  48,_, 49,_, _,_, _,_, _,_, _,_, _,_, _,_,\n  _,_, _,_, _,_, _,_, _,_, _,_, _,_, _,_\n\nNUMA domain 5\n  64,_, 65,_, _,_, _,_, _,_, _,_, _,_, _,_,\n  _,_, _,_, _,_, _,_, _,_, _,_, _,_, _,_\n\nNUMA domain 6\n  80,_, 81,_, _,_, _,_, _,_, _,_, _,_, _,_,\n  _,_, _,_, _,_, _,_, _,_, _,_, _,_, _,_\n\nNUMA domain 7\n  96,_, 97,_, _,_, _,_, _,_, _,_, _,_, _,_,\n  _,_, _,_, _,_, _,_, _,_, _,_, _,_, _,_\n\nNUMA domain 8\n  112,_, 113,_, _,_, _,_, _,_, _,_, _,_, _,_,\n  _,_, _,_, _,_, _,_, _,_, _,_, _,_, _,_\n\n\n# = Julia thread, # = Julia thread on HT, # = >1 Julia thread\n\n(Mapping: 1 => 0, 2 => 16, 3 => 32, 4 => 48, 5 => 64, ...)\n","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"There is much more, though. Rather than Julia threads you can highlight BLAS threads (after you've pinned them) with blas=true. If you're in a SLURM allocation, you might want to give slurm=true a try. For more, please check out the threadinfo() documentation.","category":"page"},{"location":"examples/ex_pinning_julia_threads/#Unpinning","page":"Pinning Julia Threads","title":"Unpinning","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"We provide functions unpinthread(threadid) and unpinthreads() to unpin a specific or all Julia threads, respectively. This is realized by setting the thread affinity mask to all ones.","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"As an alternative, you might also want to consider using pinthreads(:random) for \"fake unpinning\". While technically not really unpinning the threads, it's often a better choice (e.g. for benchmarks) as it does randomize the thread placing but keeps it fixed to reduce fluctuations.","category":"page"},{"location":"examples/ex_pinning_julia_threads/#Default-pinning-(for-package-authors)","page":"Pinning Julia Threads","title":"Default pinning (for package authors)","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"If you're developing a package you may want to provide a reasonable default pinning. If you would naively use pinthreads for this, you would enforce a certain pinning irrespective of what the user might have specified manually. To avoid this, you can set force=false in your pinthreads call, e.g. pinthreads(:cores; force=false). This way, a user can overwrite your default pinning (:cores in this example), e.g. by calling pinthreads manually before running your package code.","category":"page"},{"location":"examples/ex_pinning_julia_threads/#JULIA_PIN-environment-variable","page":"Pinning Julia Threads","title":"JULIA_PIN environment variable","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"In some scenarios, you may want to specify the desired pinning strategy through an environment variable rather than hardcoding it in the source code (e.g. as a strict pinthreads(:cores) call). This is possible if you set JULIA_PIN in conjuction with using pinthreads(...; force=false). This way, the hardcoded is strategy is only used if JULIA_PIN is not set. Otherwise, the value of the environment variable takes precedence. Note that JULIA_PIN may be set to any symbol that is supported by pinthreads. For now, specifying the CPU IDs manually isn't supported (please open an issue or a PR if you need this).","category":"page"},{"location":"refs/api_other/#api_other","page":"API - Other","title":"API - Other","text":"","category":"section"},{"location":"refs/api_other/#api_stabletasks","page":"API - Other","title":"Sticky and type-stable tasks","text":"","category":"section"},{"location":"refs/api_other/","page":"API - Other","title":"API - Other","text":" \nThreadPinning.@spawn see StableTasks.jl\nThreadPinning.@fetch see StableTasks.jl\nThreadPinning.@spawnat see StableTasks.jl\nThreadPinning.@fetchfrom see StableTasks.jl","category":"page"},{"location":"refs/api_other/#Thread-IDs","page":"API - Other","title":"Thread IDs","text":"","category":"section"},{"location":"refs/api_other/","page":"API - Other","title":"API - Other","text":" \nThreadPinning.threadids see ThreadPinningCore.jl","category":"page"},{"location":"examples/ex_mpi/#mpi_threads","page":"MPI + Threads","title":"MPI + Threads","text":"","category":"section"},{"location":"examples/ex_mpi/","page":"MPI + Threads","title":"MPI + Threads","text":"ThreadPinning.jl has dedicated support for pinning Julia threads of MPI ranks in MPI applications, see Querying - MPI and Pinning - MPI. Note that you can use these tools irrespective of whether your MPI applications is pure (i.e. each MPI rank runs a single Julia thread) or hybrid (i.e. each MPI ranks runs multiple Julia threads). We demonstrate this with a simple example below.","category":"page"},{"location":"examples/ex_mpi/","page":"MPI + Threads","title":"MPI + Threads","text":"note: Note\nIf your MPI application runs under SLURM (or a similar job scheduler), you may want to consider using the pinning options of SLURM to control the placement of the MPI ranks on the nodes, potentially in conjuction with pinthreads(:affinitymask). See External Affinity Mask for more information.","category":"page"},{"location":"examples/ex_mpi/#Example-code","page":"MPI + Threads","title":"Example code","text":"","category":"section"},{"location":"examples/ex_mpi/","page":"MPI + Threads","title":"MPI + Threads","text":"using ThreadPinning\nusing MPI\n\nMPI.Init()\nrank = MPI.Comm_rank(MPI.COMM_WORLD)\nnthreads = Threads.nthreads()\n\n# print system overview\nif rank == 0\n    for inuma in 1:nnuma()\n        println(\"NUMA node $(inuma): \", numa(inuma))\n    end\n    println(\"\\n\")\nend\n\n# print where julia threads are running (before pinning)\nhostnames = mpi_gethostnames()\ncpuids_before = mpi_getcpuids()\nif rank == 0\n    println(\"BEFORE: Where are the Julia threads of the MPI ranks running?\")\n    for r in 0:length(hostnames)-1\n        println(\"\\trank $r is running $(nthreads) Julia threads on the CPU-threads \", cpuids_before[r], \" of node \", hostnames[r])\n    end\n    println(\"\\n\")\nend\n\n# on each node, pin threads of local MPI ranks to NUMA domains in a round-robin fashion\nmpi_pinthreads(:numa)\n\n# print where julia threads are running (after pinning)\ncpuids_after = mpi_getcpuids()\nif rank == 0\n    println(\"AFTER: Where are the Julia threads of the MPI ranks running?\")\n    for r in 0:length(hostnames)-1\n        println(\"\\trank $r is running $(nthreads) Julia threads on the CPU-threads \", cpuids_after[r], \" of node \", hostnames[r])\n    end\nend","category":"page"},{"location":"examples/ex_mpi/#Pure-MPI","page":"MPI + Threads","title":"Pure MPI","text":"","category":"section"},{"location":"examples/ex_mpi/","page":"MPI + Threads","title":"MPI + Threads","text":"Details: 4 MPI ranks, no multithreading, on a single node.","category":"page"},{"location":"examples/ex_mpi/","page":"MPI + Threads","title":"MPI + Threads","text":"NUMA node 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]\nNUMA node 2: [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]\nNUMA node 3: [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]\nNUMA node 4: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]\nNUMA node 5: [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207]\nNUMA node 6: [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223]\nNUMA node 7: [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]\nNUMA node 8: [112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]\n\n\nBEFORE: Where are the Julia threads of the MPI ranks running?\n\trank 0 is running 1 Julia threads on the CPU-threads [123] of node nid004219\n\trank 1 is running 1 Julia threads on the CPU-threads [24] of node nid004219\n\trank 2 is running 1 Julia threads on the CPU-threads [11] of node nid004219\n\trank 3 is running 1 Julia threads on the CPU-threads [192] of node nid004219\n\n\nAFTER: Where are the Julia threads of the MPI ranks running?\n\trank 0 is running 1 Julia threads on the CPU-threads [0] of node nid004219\n\trank 1 is running 1 Julia threads on the CPU-threads [16] of node nid004219\n\trank 2 is running 1 Julia threads on the CPU-threads [32] of node nid004219\n\trank 3 is running 1 Julia threads on the CPU-threads [48] of node nid004219","category":"page"},{"location":"examples/ex_mpi/#Hybrid-MPI-Threads-(single-node)","page":"MPI + Threads","title":"Hybrid MPI + Threads (single node)","text":"","category":"section"},{"location":"examples/ex_mpi/","page":"MPI + Threads","title":"MPI + Threads","text":"Details: 4 MPI ranks, each running two Julia threads, on a single node.","category":"page"},{"location":"examples/ex_mpi/","page":"MPI + Threads","title":"MPI + Threads","text":"NUMA node 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]\nNUMA node 2: [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]\nNUMA node 3: [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]\nNUMA node 4: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]\nNUMA node 5: [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207]\nNUMA node 6: [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223]\nNUMA node 7: [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]\nNUMA node 8: [112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]\n\n\nBEFORE: Where are the Julia threads of the MPI ranks running?\n\trank 0 is running 2 Julia threads on the CPU-threads [127, 161] of node nid004219\n\trank 1 is running 2 Julia threads on the CPU-threads [96, 72] of node nid004219\n\trank 2 is running 2 Julia threads on the CPU-threads [105, 255] of node nid004219\n\trank 3 is running 2 Julia threads on the CPU-threads [192, 196] of node nid004219\n\n\nAFTER: Where are the Julia threads of the MPI ranks running?\n\trank 0 is running 2 Julia threads on the CPU-threads [0, 1] of node nid004219\n\trank 1 is running 2 Julia threads on the CPU-threads [16, 17] of node nid004219\n\trank 2 is running 2 Julia threads on the CPU-threads [32, 33] of node nid004219\n\trank 3 is running 2 Julia threads on the CPU-threads [48, 49] of node nid004219","category":"page"},{"location":"examples/ex_mpi/#Hybrid-MPI-Threads-(multiple-nodes)","page":"MPI + Threads","title":"Hybrid MPI + Threads (multiple nodes)","text":"","category":"section"},{"location":"examples/ex_mpi/","page":"MPI + Threads","title":"MPI + Threads","text":"Details: 16 MPI ranks, each running two Julia threads, distributed across 4 nodes (4 MPI ranks per node).","category":"page"},{"location":"examples/ex_mpi/","page":"MPI + Threads","title":"MPI + Threads","text":"NUMA node 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]\nNUMA node 2: [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]\nNUMA node 3: [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]\nNUMA node 4: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]\nNUMA node 5: [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207]\nNUMA node 6: [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223]\nNUMA node 7: [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]\nNUMA node 8: [112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]\n\n\nBEFORE: Where are the Julia threads of the MPI ranks running?\n\trank 0 is running 2 Julia threads on the CPU-threads [127, 253] of node nid004406\n\trank 1 is running 2 Julia threads on the CPU-threads [113, 182] of node nid004406\n\trank 2 is running 2 Julia threads on the CPU-threads [109, 138] of node nid004406\n\trank 3 is running 2 Julia threads on the CPU-threads [26, 115] of node nid004406\n\trank 4 is running 2 Julia threads on the CPU-threads [4, 146] of node nid005218\n\trank 5 is running 2 Julia threads on the CPU-threads [101, 236] of node nid005218\n\trank 6 is running 2 Julia threads on the CPU-threads [42, 255] of node nid005218\n\trank 7 is running 2 Julia threads on the CPU-threads [8, 90] of node nid005218\n\trank 8 is running 2 Julia threads on the CPU-threads [80, 237] of node nid005908\n\trank 9 is running 2 Julia threads on the CPU-threads [23, 198] of node nid005908\n\trank 10 is running 2 Julia threads on the CPU-threads [5, 47] of node nid005908\n\trank 11 is running 2 Julia threads on the CPU-threads [54, 26] of node nid005908\n\trank 12 is running 2 Julia threads on the CPU-threads [42, 143] of node nid005915\n\trank 13 is running 2 Julia threads on the CPU-threads [8, 120] of node nid005915\n\trank 14 is running 2 Julia threads on the CPU-threads [238, 217] of node nid005915\n\trank 15 is running 2 Julia threads on the CPU-threads [27, 159] of node nid005915\n\n\nAFTER: Where are the Julia threads of the MPI ranks running?\n\trank 0 is running 2 Julia threads on the CPU-threads [0, 1] of node nid004406\n\trank 1 is running 2 Julia threads on the CPU-threads [16, 17] of node nid004406\n\trank 2 is running 2 Julia threads on the CPU-threads [32, 33] of node nid004406\n\trank 3 is running 2 Julia threads on the CPU-threads [48, 49] of node nid004406\n\trank 4 is running 2 Julia threads on the CPU-threads [0, 1] of node nid005218\n\trank 5 is running 2 Julia threads on the CPU-threads [16, 17] of node nid005218\n\trank 6 is running 2 Julia threads on the CPU-threads [32, 33] of node nid005218\n\trank 7 is running 2 Julia threads on the CPU-threads [48, 49] of node nid005218\n\trank 8 is running 2 Julia threads on the CPU-threads [0, 1] of node nid005908\n\trank 9 is running 2 Julia threads on the CPU-threads [16, 17] of node nid005908\n\trank 10 is running 2 Julia threads on the CPU-threads [32, 33] of node nid005908\n\trank 11 is running 2 Julia threads on the CPU-threads [48, 49] of node nid005908\n\trank 12 is running 2 Julia threads on the CPU-threads [0, 1] of node nid005915\n\trank 13 is running 2 Julia threads on the CPU-threads [16, 17] of node nid005915\n\trank 14 is running 2 Julia threads on the CPU-threads [32, 33] of node nid005915\n\trank 15 is running 2 Julia threads on the CPU-threads [48, 49] of node nid005915","category":"page"},{"location":"examples/ex_distributed/#distributed_threads","page":"Distributed.jl + Threads","title":"Distributed.jl + Threads","text":"","category":"section"},{"location":"examples/ex_distributed/","page":"Distributed.jl + Threads","title":"Distributed.jl + Threads","text":"ThreadPinning.jl has dedicated support for pinning Julia threads of Julia workers (Distributed.jl) in multi-processing applications, see Querying - Distributed.jl and Pinning - Distributed.jl. Note that you can use these tools irrespective of whether your parallel application is pure (i.e. each Julia workers runs a single Julia thread) or hybrid (i.e. each Julia worker runs multiple Julia threads).","category":"page"},{"location":"examples/ex_distributed/#Basic-example","page":"Distributed.jl + Threads","title":"Basic example","text":"","category":"section"},{"location":"examples/ex_distributed/","page":"Distributed.jl + Threads","title":"Distributed.jl + Threads","text":"julia> using Distributed\n\njulia> withenv(\"JULIA_NUM_THREADS\" => 2) do\n           addprocs(4) # spawn 4 workers with 2 threads each\n       end\n4-element Vector{Int64}:\n 2\n 3\n 4\n 5\n\njulia> @everywhere using ThreadPinning\n\njulia> distributed_getcpuids()\nDict{Int64, Vector{Int64}} with 4 entries:\n  5 => [246, 185]\n  4 => [198, 99]\n  2 => [135, 226]\n  3 => [78, 184]\n\njulia> distributed_getispinned() # none pinned yet\nDict{Int64, Vector{Bool}} with 4 entries:\n  5 => [0]\n  4 => [0]\n  2 => [0]\n  3 => [0]\n\njulia> distributed_pinthreads(:sockets) # pin to sockets (round-robin)\n\njulia> distributed_getispinned() # all pinned\nDict{Int64, Vector{Bool}} with 4 entries:\n  5 => [1, 1]\n  4 => [1, 1]\n  2 => [1, 1]\n  3 => [1, 1]\n\njulia> distributed_getcpuids()\nDict{Int64, Vector{Int64}} with 4 entries:\n  5 => [66, 67]\n  4 => [2, 3]\n  2 => [0, 1]\n  3 => [64, 65]\n\njulia> socket(1, 1:4), socket(2, 1:4) # check\n([0, 1, 2, 3], [64, 65, 66, 67])\n\njulia> distributed_pinthreads(:numa) # pin to numa domains (round-robin)\n\njulia> distributed_getcpuids()\nDict{Int64, Vector{Int64}} with 4 entries:\n  5 => [48, 49]\n  4 => [32, 33]\n  2 => [0, 1]\n  3 => [16, 17]\n\njulia> numa(1, 1:2), numa(2, 1:2), numa(3, 1:2), numa(4, 1:2) # check\n([0, 1], [16, 17], [32, 33], [48, 49])","category":"page"},{"location":"refs/api_querying/#api_querying","page":"API - Querying","title":"API - Querying","text":"","category":"section"},{"location":"refs/api_querying/#threadinfo","page":"API - Querying","title":"threadinfo","text":"","category":"section"},{"location":"refs/api_querying/","page":"API - Querying","title":"API - Querying","text":"threadinfo","category":"page"},{"location":"refs/api_querying/#ThreadPinning.threadinfo","page":"API - Querying","title":"ThreadPinning.threadinfo","text":"threadinfo(;\n    groupby = :sockets,\n    threadpool = :default,\n    blas = false,\n    slurm = false,\n    hints = false,\n    compact = true,\n    hyperthreads = SysInfo.hyperthreading_is_enabled(),\n    efficiency = SysInfo.ncorekinds() > 1,\n    masks = false,\n    coregaps = SysInfo.hyperthreading_is_enabled(),\n    logical = false,\n    color = true,\n    blocksize = choose_blocksize()\n)\n\nPrint information about Julia threads, e.g. on which CPU-threads (i.e. cores if hyperthreading is disabled) they are running.\n\nKeyword arguments\n\ngroupby: Options are :sockets, :numa, :cores, or :none.\nthreadpool: Only consider Julia threads in the given thread pool.                                 Supported values are :default, :interactive, and                                 :all.\nblas: Visualize BLAS threads instead of Julia threads.\nslurm: Only show the part of the system that is covered by the active SLURM allocation.\nhints: Try to give some hints about how to improve the threading related settings.\ncompact: Toggle between compact and \"cores before hyperthreads\" ordering.\nhyperthreads: If true, we (try to) highlight CPU-threads that aren't the first threads within a CPU-core.\nefficiency: If true, we highlight (underline) CPU-threads that belong to efficiency cores.\nmasks: Show the affinity masks of all Julia threads.\ncoregaps: Put an extra space (\"gap\") between different CPU-cores, when printing.\nlogical: Toggle between logical and \"physical\" CPU-thread indices.\ncolor: Toggle between colored and black-and-white output.\nblocksize: Wrap to a new line after blocksize many CPU-threads.  May also be set to :numa in which case the line break will occur after each numa domain.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#Querying","page":"API - Querying","title":"Querying","text":"","category":"section"},{"location":"refs/api_querying/","page":"API - Querying","title":"API - Querying","text":"getcpuids\ngetcpuid\nispinned\ngetispinned\ngetaffinity\nprintaffinity\nprintaffinities\nvisualize_affinity\ngetnumanode\ngetnumanodes","category":"page"},{"location":"refs/api_querying/#ThreadPinning.getcpuids","page":"API - Querying","title":"ThreadPinning.getcpuids","text":"getcpuids(; threadpool = :default)\n\nReturns the IDs of the CPU-threads on which the Julia threads are currently running on.\n\nThe keyword argument threadpool (default: :default) may be used to specify a specific thread pool.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.getcpuid","page":"API - Querying","title":"ThreadPinning.getcpuid","text":"getcpuid(; threadid = nothing)\n\nReturns the ID of the CPU thread on which a Julia thread is currently running.\n\nIf threadid=nothing (default), we query the id directly from the calling thread.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.ispinned","page":"API - Querying","title":"ThreadPinning.ispinned","text":"ispinned(; threadid = Threads.threadid())\n\nReturns true if the thread is pinned, that is, if it has an affinity mask that highlights a single CPU-thread.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.getispinned","page":"API - Querying","title":"ThreadPinning.getispinned","text":"getispinned(; threadpool = :default)\n\nReturns the results of ispinned for all Julia threads.\n\nThe keyword argument threadpool (default: :default) may be used to specify a specific thread pool.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.getaffinity","page":"API - Querying","title":"ThreadPinning.getaffinity","text":"getaffinity(; threadid = Threads.threadid(), cutoff = cpuidlimit())\n\nGet the thread affinity of a Julia thread. Returns the affinity mask as a vector of zeros and ones. By default, the mask is cut off at Sys.CPU_THREADS. This can be tuned via the cutoff keyword argument (nothing means no cutoff).\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.printaffinity","page":"API - Querying","title":"ThreadPinning.printaffinity","text":"printaffinity(; threadid::Integer = Threads.threadid())\n\nPrint the affinity mask of the Julia thread.\n\nThe keyword argument groupby may be used to change how CPU-threads are grouped visually. It defaults to groupby=:socket. Other valid values are :numa and :core.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.printaffinities","page":"API - Querying","title":"ThreadPinning.printaffinities","text":"printaffinities(; threadpool = :default, kwargs...)\n\nPrint the affinity masks of all Julia threads. See printaffinity for options.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.visualize_affinity","page":"API - Querying","title":"ThreadPinning.visualize_affinity","text":"Visualize the affinity mask of a Julia thread. Many of the keyword options of threadinfo work here as well.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.getnumanode","page":"API - Querying","title":"ThreadPinning.getnumanode","text":"getnumanode(; threadid = nothing)\n\nReturns the ID (starting at zero) of the NUMA node corresponding to the CPU thread on which the calling thread is currently running. A threadid may be provided to consider a Julia thread that is different from the calling one.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.getnumanodes","page":"API - Querying","title":"ThreadPinning.getnumanodes","text":"getnumanodes(; threadpool = :default)\n\nReturns the IDs (starting at zero) of the NUMA nodes corresponding to the CPU threads on which the Julia threads are currently running.\n\nThe keyword argument threadpool (default: :default) may be used to consider only those Julia threads that belong to a specific thread pool.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#api_logical","page":"API - Querying","title":"Querying - Logical","text":"","category":"section"},{"location":"refs/api_querying/","page":"API - Querying","title":"API - Querying","text":"core\nnuma\nsocket\nnode\ncores\nnumas\nsockets\nThreadPinning.cpuids\nThreadPinning.id\nThreadPinning.cpuid","category":"page"},{"location":"refs/api_querying/#ThreadPinning.core","page":"API - Querying","title":"ThreadPinning.core","text":"Returns the CPU IDs that belong to core i (logical index, starts at 1). Set shuffle=true to randomize.\n\nOptional second argument: Logical indices to select a subset of the CPU-threads.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.numa","page":"API - Querying","title":"ThreadPinning.numa","text":"Returns the CPU IDs that belong to the ith NUMA domain (logical index, starts at 1). By default, an \"cores before hyperthreads\" ordering is used. Set compact=true if you want compact ordering. Set shuffle=true to randomize.\n\nOptional second argument: Logical indices to select a subset of the CPU-threads.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.socket","page":"API - Querying","title":"ThreadPinning.socket","text":"Returns the CPU IDs that belong to the ith CPU/socket (logical index, starts at 1). By default, an \"cores before hyperthreads\" ordering is used. Set compact=true if you want compact ordering. Set shuffle=true to randomize.\n\nOptional second argument: Logical indices to select a subset of the CPU-threads.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.node","page":"API - Querying","title":"ThreadPinning.node","text":"Returns all CPU IDs of the system/compute node (logical index, starts at 1). By default, an \"cores before hyperthreads\" ordering is used. Set compact=true if you want compact ordering. Set shuffle=true to randomize.\n\nOptional second argument: Logical indices to select a subset of the CPU-threads.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.cores","page":"API - Querying","title":"ThreadPinning.cores","text":"Returns the CPU IDs of the system as obtained by a round-robin scattering between CPU cores. This is the same as nodes(; compact=false). Set shuffle=true to randomize.\n\nOptional first argument: Logical indices to select a subset of the sockets.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.numas","page":"API - Querying","title":"ThreadPinning.numas","text":"Returns the CPU IDs of the system as obtained by a round-robin scattering between NUMA domains. Within each NUMA domain, a round-robin ordering among CPU cores is used (\"cores before hyperthreads\"). Provide compact=true to get compact ordering within each NUMA domain. Set shuffle=true to randomize.\n\nOptional first argument: Logical indices to select a subset of the sockets.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.sockets","page":"API - Querying","title":"ThreadPinning.sockets","text":"Returns the CPU IDs of the system as obtained by a round-robin scattering between sockets. By default, within each socket, a round-robin ordering among CPU cores is used (\"cores before hyperthreads\"). Provide compact=true to get compact ordering within each socket. Set shuffle=true to randomize.\n\nOptional first argument: Logical indices to select a subset of the sockets.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.cpuids","page":"API - Querying","title":"ThreadPinning.cpuids","text":"All valid CPU IDs of the system (sorted).\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.id","page":"API - Querying","title":"ThreadPinning.id","text":"Returns the logical index (starts at 1) that corresponds to the given CPU ID (\"physical\" OS index).\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.cpuid","page":"API - Querying","title":"ThreadPinning.cpuid","text":"Returns the CPU ID (\"physical\" OS index) that corresponds to the given logical index (starts at 1).\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#Querying-System","page":"API - Querying","title":"Querying - System","text":"","category":"section"},{"location":"refs/api_querying/","page":"API - Querying","title":"API - Querying","text":"ncputhreads\nncores\nnnuma\nnsockets\nncorekinds\nnsmt\nisefficiencycore\nishyperthread\nhyperthreading_is_enabled","category":"page"},{"location":"refs/api_querying/#ThreadPinning.ncputhreads","page":"API - Querying","title":"ThreadPinning.ncputhreads","text":"Number of CPU-threads\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.ncores","page":"API - Querying","title":"ThreadPinning.ncores","text":"Number of cores (i.e. excluding hyperthreads)\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.nnuma","page":"API - Querying","title":"ThreadPinning.nnuma","text":"Number of NUMA nodes\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.nsockets","page":"API - Querying","title":"ThreadPinning.nsockets","text":"Number of CPU-sockets / CPUs\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.ncorekinds","page":"API - Querying","title":"ThreadPinning.ncorekinds","text":"Number of different kinds of cores (e.g. efficiency and performance cores).\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.nsmt","page":"API - Querying","title":"ThreadPinning.nsmt","text":"The number of SMT-threads in a core. If this number varies between different cores, the maximum is returned.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.isefficiencycore","page":"API - Querying","title":"ThreadPinning.isefficiencycore","text":"Returns true if the given CPU-thread lies inside of a CPU-core that has the highest power efficiency of all the CPU-cores (i.e. an efficiency value of 1). If there is only a single CPU-core kind, the return value is false for all CPU IDs.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.ishyperthread","page":"API - Querying","title":"ThreadPinning.ishyperthread","text":"Check whether the given CPU-thread is a SMT-thread / \"hyperthread\" (i.e. it is not the first CPU-thread in the CPU-core).\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.hyperthreading_is_enabled","page":"API - Querying","title":"ThreadPinning.hyperthreading_is_enabled","text":"Check whether simultaneous multithreading (SMT) / \"hyperthreading\" is enabled.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#Querying-OpenBLAS","page":"API - Querying","title":"Querying - OpenBLAS","text":"","category":"section"},{"location":"refs/api_querying/","page":"API - Querying","title":"API - Querying","text":"openblas_getaffinity\nopenblas_getcpuids\nopenblas_getcpuid\nopenblas_ispinned\nopenblas_printaffinities\nopenblas_printaffinity","category":"page"},{"location":"refs/api_querying/#ThreadPinning.openblas_getaffinity","page":"API - Querying","title":"ThreadPinning.openblas_getaffinity","text":"openblas_getaffinity(; threadid, convert = true)\n\nQuery the affinity of the OpenBLAS thread with the given threadid (typically 1:BLAS.get_num_threads()). By default, returns a vector respresenting the mask. If convert=false a Ccpu_set_t is returned instead.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.openblas_getcpuids","page":"API - Querying","title":"ThreadPinning.openblas_getcpuids","text":"openblas_getcpuids()\n\nGet the ids of the CPU threads on which the OpenBLAS threads are running on according to their affinity. See openblas_getcpuid for more information.\"\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.openblas_getcpuid","page":"API - Querying","title":"ThreadPinning.openblas_getcpuid","text":"openblas_getcpuid(; threadid)\n\nGet the id of the CPU thread on which the OpenBLAS thread with the given threadid is running on according to its affinity.\n\nNote: If the OpenBLAS thread has not been pinned before, this function will error because the affinity mask highlights more than a single CPU thread by default.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.openblas_ispinned","page":"API - Querying","title":"ThreadPinning.openblas_ispinned","text":"openblas_ispinned(; threadid)\n\nCheck if the OpenBLAS thread is pinned to a single CPU thread.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.openblas_printaffinities","page":"API - Querying","title":"ThreadPinning.openblas_printaffinities","text":"Print the affinities of all OpenBLAS threads.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.openblas_printaffinity","page":"API - Querying","title":"ThreadPinning.openblas_printaffinity","text":"openblas_printaffinity(; threadid)\n\nPrint the affinity of an OpenBLAS thread.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#api_mpi_querying","page":"API - Querying","title":"Querying - MPI","text":"","category":"section"},{"location":"refs/api_querying/","page":"API - Querying","title":"API - Querying","text":"mpi_getcpuids\nmpi_gethostnames\nmpi_getlocalrank","category":"page"},{"location":"refs/api_querying/#ThreadPinning.mpi_getcpuids","page":"API - Querying","title":"ThreadPinning.mpi_getcpuids","text":"On rank 0, this function returns a Dict{Int, Vector{Int}} where the keys are the MPI rank ids and the values are the CPU IDs of the CPU-threads that are currently running the Julia threads of the MPI rank. Returns nothing on all other ranks.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.mpi_gethostnames","page":"API - Querying","title":"ThreadPinning.mpi_gethostnames","text":"On rank 0, this function returns a Dict{Int, String} where the keys are the MPI rank ids and the values are the hostnames of the nodes that are currently hosting the respective MPI ranks. Returns nothing on all other ranks.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.mpi_getlocalrank","page":"API - Querying","title":"ThreadPinning.mpi_getlocalrank","text":"Returns a node-local rank id (starts at zero). Nodes are identified based on their hostnames (gethostname). On each node, ranks are ordered based on their global rank id.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#api_distributed_querying","page":"API - Querying","title":"Querying - Distributed.jl","text":"","category":"section"},{"location":"refs/api_querying/","page":"API - Querying","title":"API - Querying","text":"distributed_getcpuids\ndistributed_gethostnames\ndistributed_getispinned","category":"page"},{"location":"refs/api_querying/#ThreadPinning.distributed_getcpuids","page":"API - Querying","title":"ThreadPinning.distributed_getcpuids","text":"Returns a Dict{Int, Vector{Int}} where the keys are the pids of the Julia workers and the values are the CPU IDs of the CPU-threads that are currently running the Julia threads of the worker.\n\nIf include_master=true, the master process (Distributed.myid() == 1) will be included.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.distributed_gethostnames","page":"API - Querying","title":"ThreadPinning.distributed_gethostnames","text":"Returns a Dict{Int, String} where the keys are the pids of the Julia workers and the values are the hostnames of the nodes that are currently hosting the respective workers.\n\nIf include_master=true, the master process (Distributed.myid() == 1) will be included.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_querying/#ThreadPinning.distributed_getispinned","page":"API - Querying","title":"ThreadPinning.distributed_getispinned","text":"Returns a Dict{Int, Vector{Bool}} where the keys are the pids of the Julia workers and the values are the results of ThreadPinning.ispinned evaluated for all Julia threads of a worker.\n\nIf include_master=true, the master process (Distributed.myid() == 1) will be included.\n\n\n\n\n\n","category":"function"},{"location":"examples/ex_blas/#Pinning-OpenBLAS-Threads","page":"Pinning BLAS Threads","title":"Pinning OpenBLAS Threads","text":"","category":"section"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"Almost all of the pinning (and querying) functions have counterparts that are prefixed by openblas_. You can use these variants to control OpenBLAS threads in the same way as the regular Julia threads. Example: ","category":"page"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"using ThreadPinning\nopenblas_pinthreads(:cores)","category":"page"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"As for visualization, you can use threadinfo(; blas=true) to visualize the placement of the OpenBLAS threads instead of Julia threads.","category":"page"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"note: Note\nFor technical reasons, we can't query the CPU-thread on which an OpenBLAS thread is running before the thread has been pinned. For this reason, openblas_getcpuid, and all functionality that relies on it, will only work after pinning. Otherwise, these calls will throw an error. Note that printing the affinities of the OpenBLAS threads (openblas_printaffinities) always works.","category":"page"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"(Image: openblas)","category":"page"},{"location":"examples/ex_blas/#Beware:-Interaction-between-Julia-threads-and-BLAS-threads","page":"Pinning BLAS Threads","title":"Beware: Interaction between Julia threads and BLAS threads","text":"","category":"section"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"If one runs a multithreaded Julia code that, on each thread, performs linear algebra operations (BLAS/LAPACK calls) one can easily run into performance issues due to an oversubscription of cores by Julia and BLAS threads (see Background information below for more information). Fortunately, ThreadPinning.jl provides some (basic) autochecking functionality that highlights potential problems and suggests improvements. Concretely, you can provide the keyword argument hints=true to threadinfo. In this case, we try to provide concrete notes and warnings that (hopefully) help you to tune your thread-related settings.","category":"page"},{"location":"examples/ex_blas/#blas_background","page":"Pinning BLAS Threads","title":"Background information","text":"","category":"section"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"Relevant discourse threads, see here and here.","category":"page"},{"location":"examples/ex_blas/#OpenBLAS","page":"Pinning BLAS Threads","title":"OpenBLAS","text":"","category":"section"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"If OPENBLAS_NUM_THREADS=1, OpenBLAS uses the calling Julia thread(s) to run BLAS computations, i.e. it \"reuses\" the Julia thread that runs a computation.\nIf OPENBLAS_NUM_THREADS=N>1, OpenBLAS creates and manages its own pool of BLAS threads (N in total). There is one BLAS thread pool (for all Julia threads).\nJulia default: OPENBLAS_NUM_THREADS=8 (Julia version ≤ 1.8) and OPENBLAS_NUM_THREADS=Sys.CPU_THREADS (Julia version ≥ 1.8).","category":"page"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"When you start Julia in multithreaded mode, i.e. julia -tX or JULIA_NUM_THREADS=X, it is generally recommended to set OPENBLAS_NUM_THREADS=1 or, equivalently, BLAS.set_num_threads(1). Given the behavior above, increasing the number of BLAS threads to N>1 can very easily lead to worse performance, in particular when N<<X! Hence, if you want to or need to deviate from unity, make sure to \"jump\" from OPENBLAS_NUM_THREADS=1 to OPENBLAS_NUM_THREADS=# of cores or similar.","category":"page"},{"location":"examples/ex_blas/#Intel-MKL","page":"Pinning BLAS Threads","title":"Intel MKL","text":"","category":"section"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"Given MKL_NUM_THREADS=N, MKL starts N BLAS threads per Julia thread that makes a BLAS call.\nDefault: MKL_NUM_THREADS=# of physical cores, i.e. excluding hyperthreads. (Verified experimentally but would be good to find a source for this.)","category":"page"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"When you start Julia in multithreaded mode, i.e. julia -tX or JULIA_NUM_THREADS=X, we recommend to set MKL_NUM_THREADS=(# of cores)/X or, equivalently, BLAS.set_num_threads((# of cores)/X) (after using MKL). Unfortunately, the default is generally suboptimal as soon as you don't run Julia with a single thread. Hence, make sure to tune the settings appropriately.","category":"page"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"Side comment: It is particularly bad / confusing that OpenBLAS and MKL behave very differently for multithreaded Julia.","category":"page"},{"location":"examples/ex_blas/","page":"Pinning BLAS Threads","title":"Pinning BLAS Threads","text":"warning: Warning\nBe aware that calling an MKL function (for the first time) can spoil the pinning of Julia threads! A concrete example is discussed here. TLDR: You want to make sure that MKL_DYNAMIC=false. Apart from setting the environment variable you can also dynamically call ThreadPinning.MKL.mkl_set_dynamic(0). Note that, by default, ThreadPinning.jl will warn you if you call one of the pinning functions while MKL_DYNAMIC=true.","category":"page"},{"location":"examples/ex_pinning_tasks/#Pinning-Julia-Tasks","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"","category":"section"},{"location":"examples/ex_pinning_tasks/#Task-based-multithreading","page":"Pinning Julia Tasks","title":"Task-based multithreading","text":"","category":"section"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"It is important to note that Julia implements task-based multithreading: M dynamically created user tasks get scheduled onto N Julia threads. By default, task scheduling is dynamic and is handled by Julia's built-in scheduler. Similar to how the operating system's scheduler can freely move Julia threads between CPU threads, Julia's scheduler can move tasks between Julia threads. Consequently, before pinning, a user cannot reliably predict on which Julia thread a task will run and on which CPU thread a Julia thread will run (see the visualization below).","category":"page"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"(Image: tasks_threads_cores)","category":"page"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"The primary purpose of ThreadPinning.jl is to allow you to pin Julia threads to CPU-threads. In this sense, it enables you to supersede the dynamic OS scheduler (right part in the image above). However, the dynamic scheduling of Julia tasks (left part in the image above) remains as is.","category":"page"},{"location":"examples/ex_pinning_tasks/#Static-scheduling-and-*sticky*-tasks","page":"Pinning Julia Tasks","title":"Static scheduling and sticky tasks","text":"","category":"section"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"If you want to opt-out of Julia's dynamic task scheduling and want to \"pin\" Julia tasks to specific Julia threads, you will often need to use tools from external libraries (such as ThreadPinning.jl), as support for this in base Julia is sparse. The only official API for static scheduling of sticky tasks (i.e. tasks that stay on the Julia thread they've been spawned on) is Threads.@threads :static. In code like","category":"page"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"Threads.@threads :static for i in 1:Threads.nthreads()\n    do_something_on_thread(i)\nend","category":"page"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"it is guaranteed that each Julia thread will run precisely one sticky task that corresponds to one iteration of the loop. Hence, i may be interpreted as a Julia thread index. In fact, it is even guaranteed that the first (default) Julia thread will run the first task (iteration), the second (default) Julia thread will run the second task (iteration), and so on.","category":"page"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"warning: Warning\nBeware, the indices of the default Julia threads (as given by Threads.threadid() if called on them) actually only start at 1 in the absence of interactive threads.","category":"page"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"warning: Warning\nUnder the hood, Threads.@threads always splits up the iteration regime into Threads.nthreads() many tasks, irrespective of the length of the iteration range. In the example above, there is a one-to-one correspondence between iterations and tasks but for general iterations (say, 1:N where N > Threads.nthreads()) a task - and consequently a Julia thread - will take care of more than one iteration.","category":"page"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"The static scheduling option Threads.@threads :static is the only official built-in way to get sticky tasks. In particular, there is no sticky pendant of @spawn for manually creating tasks.","category":"page"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"ThreadPinning.jl aims to fill this gap by providing ThreadPinning.@spawnat and a few other tools. As the name suggests, this macro allows you to spawn a sticky task on a specific Julia thread, e.g. ThreadPinning.@spawnat 3 println(\"Hello from thread 3\").","category":"page"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"Using ThreadPinning.@spawnat we can rewrite the code above as","category":"page"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"@sync for i in 1:Threads.nthreads()\n    ThreadPinning.@spawnat i do_something_on_thread(i)\nend","category":"page"},{"location":"examples/ex_pinning_tasks/","page":"Pinning Julia Tasks","title":"Pinning Julia Tasks","text":"Both the task-iteration mapping and the task-thread assignment are explicitly and immediately visible here.","category":"page"},{"location":"refs/api_pinning/#API-Pinning","page":"API - Pinning","title":"API - Pinning","text":"","category":"section"},{"location":"refs/api_pinning/#Pinning","page":"API - Pinning","title":"Pinning","text":"","category":"section"},{"location":"refs/api_pinning/","page":"API - Pinning","title":"API - Pinning","text":"pinthreads\npinthread\nwith_pinthreads\nunpinthreads\nunpinthread\nsetaffinity\nsetaffinity_cpuids","category":"page"},{"location":"refs/api_pinning/#ThreadPinning.pinthreads","page":"API - Pinning","title":"ThreadPinning.pinthreads","text":"pinthreads(cpuids;\n    nthreads   = nothing,\n    force      = true,\n    warn       = is_first_pin_attempt(),\n    threadpool = :default\n)\n\nPin Julia threads to an explicit or implicit list of CPU IDs. The latter can be specified in three ways:\n\nby passing one of several predefined symbols (e.g. pinthreads(:cores) or pinthreads(:sockets)),\nby providing a logical specification via helper functions (e.g. pinthreads(numa(2, 1:4))),\nexplicitly (e.g. 0:3 or [0,12,4]).\n\nSee ??pinthreads for more information on these variants and keyword arguments.\n\nKeyword arguments\n\nIf set, the keyword argument nthreads serves as a cutoff, that is, the first min(length(cpuids), nthreads) Julia threads will get pinned.\n\nThe keyword argument threadpool can be used to indicate the pool of Julia threads that should be considered. Supported values are :default (default), :interactive, or :all. On Julia >= 1.11, there is also experimental support for :gc.\n\nIf force=false, threads will only get pinned if this is the very first pin attempt (otherwise the call is a no-op). This may be particularly useful for packages that merely want to specify an \"default pinning\" that can be overwritten by the user.\n\nThe option warn toggles general warnings, such as unwanted interference with BLAS thread settings.\n\nExtended help\n\n1) Predefined Symbols\n\n:cputhreads or :compact: successively pin to all available CPU-threads.\n:cores: spread threads across all available cores, only use hyperthreads if necessary.\n:sockets: spread threads across sockets (round-robin), only use hyperthreads if             necessary. Set compact=true to get compact pinning within each socket.\n:numa: spread threads across NUMA/memory domains (round-robin), only use hyperthreads          if necessary. Set compact=true to get compact pinning within each NUMA/memory          domain.\n:random: pin threads randomly to CPU-threads\n:current: pin threads to the CPU-threads they are currently running on\n:firstn: pin threads to CPU-threads in order according to there OS index.\n:affinitymask: pin threads to different CPU-threads in accordance with the process                  affinity. By default, hyperthreads_last=true.\n\n2) Logical Specification\n\nThe functions node, socket, numa, and core can be used to to specify CPU IDs of/within a certain domain. Moreover, the functions sockets and numas can be used to express a round-robin scatter policy between sockets or NUMA domains, respectively.\n\nExamples (domains):\n\npinthreads(socket(1, 1:3)) # pin to the first 3 cores in the first socket\npinthreads(socket(1, 1:3; compact=true)) # pin to the first 3 CPU-threads in the first socket\npinthreads(numa(2, [2,4,6])) # pin to the second, the fourth, and the sixth cores in the second NUMA/memory domain\npinthreads(node(ncores():-1:1)) # pin threads to cores in reversing order (starting at the end of the node)\npinthreads(sockets()) # scatter threads between sockets, cores before hyperthreads\n\nDifferent domains can be concatenated by providing them in a vector or as separate arguments to pinthreads.\n\nExamples (concatenation):\n\npinthreads([socket(1, 1:3), numa(2, 4:6)])\npinthreads(socket(1, 1:3), numa(2, 4:6))\n\n3) Explicit\n\nSimply provide an AbstractVector{<:Integer} of CPU IDs. The latter are expected to be \"physical\" OS indices (e.g. from hwloc or lscpu) that start at zero!\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.pinthread","page":"API - Pinning","title":"ThreadPinning.pinthread","text":"pinthread(cpuid::Integer; threadid = Threads.threadid())\n\nPin the a Julia thread to the given CPU-thread.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.with_pinthreads","page":"API - Pinning","title":"ThreadPinning.with_pinthreads","text":"with_pinthreads(f::F, args...;\n    soft = false,\n    kwargs...\n)\n\nRuns the function f with the specified pinning and restores the previous thread affinities afterwards. Typically to be used in combination with do-syntax.\n\nBy default (soft=false), before the thread affinities are restored, the Julia threads will be pinned to the CPU-threads they were running on previously.\n\nExample\n\njulia> getcpuids()\n4-element Vector{Int64}:\n  7\n 75\n 63\n  4\n\njulia> with_pinthreads(:cores) do\n           getcpuids()\n       end\n4-element Vector{Int64}:\n 0\n 1\n 2\n 3\n\njulia> getcpuids()\n4-element Vector{Int64}:\n  7\n 75\n 63\n  4\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.unpinthreads","page":"API - Pinning","title":"ThreadPinning.unpinthreads","text":"unpinthreads(; threadpool::Symbol = :default)\n\nUnpins all Julia threads by setting the affinity mask of all threads to all unity. Afterwards, the OS is free to move any Julia thread from one CPU thread to another.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.unpinthread","page":"API - Pinning","title":"ThreadPinning.unpinthread","text":"unpinthread(; threadid::Integer = Threads.threadid())\n\nUnpins the given Julia thread by setting the affinity mask to all unity. Afterwards, the OS is free to move the Julia thread from one CPU thread to another.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.setaffinity","page":"API - Pinning","title":"ThreadPinning.setaffinity","text":"setaffinity(mask; threadid = Threads.threadid())\n\nSet the affinity of a Julia thread based on the given mask (a vector of ones and zeros).\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.setaffinity_cpuids","page":"API - Pinning","title":"ThreadPinning.setaffinity_cpuids","text":"Set the affinity of a Julia thread to the given CPU-threads.\n\nExamples:\n\nsetaffinity(socket(1)) # set the affinity to the first socket\nsetaffinity(numa(2)) # set the affinity to the second NUMA domain\nsetaffinity(socket(1, 1:3)) # set the affinity to the first three cores in the first NUMA domain\nsetaffinity([1,3,5]) # set the affinity to the CPU-threads with the IDs 1, 3, and 5.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#Pinning-OpenBLAS","page":"API - Pinning","title":"Pinning - OpenBLAS","text":"","category":"section"},{"location":"refs/api_pinning/","page":"API - Pinning","title":"API - Pinning","text":"openblas_pinthreads\nopenblas_pinthread\nopenblas_unpinthreads\nopenblas_unpinthread\nopenblas_setaffinity\nopenblas_setaffinity_cpuids","category":"page"},{"location":"refs/api_pinning/#ThreadPinning.openblas_pinthreads","page":"API - Pinning","title":"ThreadPinning.openblas_pinthreads","text":"openblas_pinthreads(cpuids; nthreads = BLAS.get_num_threads())\n\nPin the OpenBLAS threads to the given CPU IDs. The optional keyword argument nthreads serves as a cutoff.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.openblas_pinthread","page":"API - Pinning","title":"ThreadPinning.openblas_pinthread","text":"openblas_pinthread(cpuid; threadid)\n\nPin the OpenBLAS thread with the given threadid to the given CPU-thread (cpuid).\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.openblas_unpinthreads","page":"API - Pinning","title":"ThreadPinning.openblas_unpinthreads","text":"openblas_unpinthreads(; threadpool = :default)\n\nUnpins all OpenBLAS threads by setting their affinity masks all unity. Afterwards, the OS is free to move any OpenBLAS thread from one CPU thread to another.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.openblas_unpinthread","page":"API - Pinning","title":"ThreadPinning.openblas_unpinthread","text":"openblas_unpinthread(; threadid)\n\nUnpins the OpenBLAS thread with the given threadid by setting its affinity mask to all unity. Afterwards, the OS is free to move the OpenBLAS thread from one CPU thread to another.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.openblas_setaffinity","page":"API - Pinning","title":"ThreadPinning.openblas_setaffinity","text":"openblas_setaffinity(mask; threadid)\n\nSet the affinity of the OpenBLAS thread with the given threadid to the given mask.\n\nThe input mask should be one of the following:\n\na BitArray to indicate the mask directly\na vector of cpuids (in which case the mask will be constructed automatically)\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.openblas_setaffinity_cpuids","page":"API - Pinning","title":"ThreadPinning.openblas_setaffinity_cpuids","text":"Set the affinity of the OpenBLAS thread to the given CPU-threads.\n\nExamples:\n\nopenblas_setaffinity_cpuids(socket(1)) # set the affinity to the first socket\nopenblas_setaffinity_cpuids(numa(2)) # set the affinity to the second NUMA domain\nopenblas_setaffinity_cpuids(socket(1, 1:3)) # set the affinity to the first three cores in the first NUMA domain\nopenblas_setaffinity_cpuids([1,3,5]) # set the affinity to the CPU-threads with the IDs 1, 3, and 5.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#api_mpi_pinning","page":"API - Pinning","title":"Pinning - MPI","text":"","category":"section"},{"location":"refs/api_pinning/","page":"API - Pinning","title":"API - Pinning","text":"mpi_pinthreads","category":"page"},{"location":"refs/api_pinning/#ThreadPinning.mpi_pinthreads","page":"API - Pinning","title":"ThreadPinning.mpi_pinthreads","text":"mpi_pinthreads(symbol; compact, kwargs...)\n\nPin the Julia threads of MPI ranks in a round-robin fashion to specific domains (e.g. sockets). Supported domains (symbol) are :sockets, :numa, and :cores.\n\nWhen calling this function on all MPI ranks, the Julia threads of the latter will be distributed in a round-robin fashion among the specified domains and will be pinned to non-overlapping ranges of CPU-threads within the domains.\n\nA multi-node setup, where MPI ranks are hosted on different nodes, is supported.\n\nIf compact=false (default), physical cores are occupied before hyperthreads. Otherwise, CPU-cores - with potentially multiple CPU-threads - are filled up one after another (compact pinning).\n\nExample:\n\nusing ThreadPinning\nusing MPI\nMPI.Init()\nmpi_pinthreads(:sockets)\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#api_distributed_pinning","page":"API - Pinning","title":"Pinning - Distributed.jl","text":"","category":"section"},{"location":"refs/api_pinning/","page":"API - Pinning","title":"API - Pinning","text":"distributed_pinthreads\ndistributed_unpinthreads","category":"page"},{"location":"refs/api_pinning/#ThreadPinning.distributed_pinthreads","page":"API - Pinning","title":"ThreadPinning.distributed_pinthreads","text":"distributed_pinthreads(symbol;\n    include_master = false,\n    compact = false,\n    nthreads_per_proc = Threads.nthreads(),\n    kwargs...)\n\nPin the Julia threads of Julia workers in a round-robin fashion to specific domains (e.g. sockets). Supported domains (symbol) are :sockets, :numa, and :cores.\n\nWhen calling this function, the Julia threads of all Julia workers will be distributed in a round-robin fashion among the specified domains and will be pinned to non-overlapping ranges of CPU-threads within the domains.\n\nA multi-node setup, where Julia workers are hosted on different nodes, is supported.\n\nIf include_master=true, the master process (Distributed.myid() == 1) will be pinned as well.\n\nIf compact=false (default), physical cores are occupied before hyperthreads. Otherwise, CPU-cores - with potentially multiple CPU-threads - are filled up one after another (compact pinning).\n\nExample:\n\nusing Distributed\naddprocs(3)\n@everywhere using ThreadPinning\ndistributed_pinthreads(:sockets)\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.distributed_unpinthreads","page":"API - Pinning","title":"ThreadPinning.distributed_unpinthreads","text":"Unpin all threads on all Julia workers.\n\nIf include_master=true, the master process (Distributed.myid() == 1) will be unpinned as well.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#Pinning-LIKWID","page":"API - Pinning","title":"Pinning - LIKWID","text":"","category":"section"},{"location":"refs/api_pinning/","page":"API - Pinning","title":"API - Pinning","text":"Besides pinthreads, we offer pinthreads_likwidpin which, ideally, should handle all inputs that are supported by the -c option of likwid-pin (e.g. S0:1-3@S1:2,4,5 or E:N:4:2:4). If you encounter an input that doesn't work as expected, please file an issue.","category":"page"},{"location":"refs/api_pinning/","page":"API - Pinning","title":"API - Pinning","text":"pinthreads_likwidpin\nlikwidpin_to_cpuids\nlikwidpin_domains","category":"page"},{"location":"refs/api_pinning/#ThreadPinning.pinthreads_likwidpin","page":"API - Pinning","title":"ThreadPinning.pinthreads_likwidpin","text":"pinthreads_likwidpin(str::AbstractString; onebased = false)\n\nPins Julia threads to CPU-threads based on the given likwid-pin compatible string. Checkout the LIKWID documentation for more information.\n\nIf the keyword argument onebased is set to true, logical indices as well as domain indices start at one instead of zero (likwid-pin default). Note, though, that this doesn't affect the explicit pinning mode where \"physical\" CPU IDs always start at zero.\n\nExamples\n\npinthreads_likwidpin(\"S0:0-3\")\npinthreads_likwidpin(\"M1:0,2,4\")\npinthreads_likwidpin(\"S:scatter\")\npinthreads_likwidpin(\"E:N:4:1:2\")\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.likwidpin_to_cpuids","page":"API - Pinning","title":"ThreadPinning.likwidpin_to_cpuids","text":"likwidpin_to_cpuids(lpstr::AbstractString; onebased = false)\n\nConvert the given likwid-pin compatible string into a CPU ID list. See pinthreads_likwidpin for more information.\n\n\n\n\n\n","category":"function"},{"location":"refs/api_pinning/#ThreadPinning.likwidpin_domains","page":"API - Pinning","title":"ThreadPinning.likwidpin_domains","text":"likwidpin_domains(; onebased = false)\n\nThe likwid-pin compatible domains that are available for the system.\n\n\n\n\n\n","category":"function"},{"location":"#ThreadPinning.jl","page":"ThreadPinning","title":"ThreadPinning.jl","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"Most notably, ThreadPinning.jl allows you","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"to pin Julia threads to specific CPU-threads (\"hardware threads\") with pinthreads and\nto obtain a visual overview of the system topology with threadinfo.","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"There is support for pinning Julia threads in hybrid Julia codes (MPI + Threads or Distributed.jl + Threads).","category":"page"},{"location":"#What-is-this-about?-(10-minutes)","page":"ThreadPinning","title":"What is this about? (10 minutes)","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"Check out my lightning talk that I gave as part of JuliaCon 2023 at MIT.","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"(Image: )","category":"page"},{"location":"#Why-pin-threads?","page":"ThreadPinning","title":"Why pin threads?","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"It can massively impact performance (especially on HPC clusters).\nIt makes performance benchmarks less noisy.\nIt is a prerequisite for hardware-performance monitoring.","category":"page"},{"location":"#Installation","page":"ThreadPinning","title":"Installation","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"The package is registered. Hence, you can simply use","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"] add ThreadPinning","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"to add the package to your Julia environment.","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"note: Note\nWhile you can install the package on all systems, only Linux is fully supported. Especially the pinning functionality does not work on other operating systems and all basic pinning calls (e.g. pinthreads(:cores)) will turn into no-ops. threadinfo(), and other querying functions, should work on all systems (although the output might be limited).","category":"page"},{"location":"#Terminology","page":"ThreadPinning","title":"Terminology","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"CPU: Chip that sits in a socket and (almost always) hosts multiple CPU-cores.\nCPU-cores: Physical processor cores of the CPU.\nCPU-threads: Hardware threads (a.k.a. \"virtual cores\") within the CPU-cores.\nCPU ID: Unique ID that identifies a specific CPU-thread. (This is somewhat inconsistent but has been chosen for brevity and backwards-compatibility reasons.)","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"If the system supports SMT (\"hyperthreading\"), there are more CPU-threads than CPU-cores (most commonly a factor of two more). Independent of the CPU vendor, we refer to all but the first CPU-threads in a core as hyperthreads. The latter are highlighted differently in output, see threadinfo().","category":"page"},{"location":"#Backends","page":"ThreadPinning","title":"Backends","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"ThreadPinning.jl is based on","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"SysInfo.jl for querying system information (based on Hwloc.jl and lscpu) and\nThreadPinningCore.jl for core pinning functionality (based on libuv).","category":"page"},{"location":"#Noteworthy-Alternatives","page":"ThreadPinning","title":"Noteworthy Alternatives","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"Simply setting JULIA_EXCLUSIVE=1 will pin Julia threads to CPU-threads in \"physical order\" (i.e. as specified by lscpu), which might or might not include hyperthreads.\npinthreads or likwid-pin (CLI tool) from LIKWID.jl\nThis discourse thread discusses issues with alternatives like numactl","category":"page"},{"location":"examples/ex_core2core_latency/#Core-to-Core-Latency","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"","category":"section"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"Let's measure the inter-core latencies of one of the compute nodes of Noctua 1 at PC2.","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"using ThreadPinning\nlatencies = ThreadPinning.bench_core2core_latency()","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"40×40 Matrix{Float64}:\n   0.0   217.05  204.85  206.0   203.3   204.95  211.7   205.2   209.5   210.1   209.65  209.3   198.7   194.95  …  271.1   267.5   265.0   260.85  266.9   267.15  265.8   266.7   265.55  258.85  262.1   263.95  269.4\n 215.55    0.0   214.65  215.15  219.8   222.1   219.55  217.1   223.1   224.7   220.25  219.45  213.2   214.6      266.6   269.45  269.85  270.6   271.25  271.1   267.45  265.65  263.15  259.85  260.85  263.2   267.45\n 224.2   214.75    0.0   216.05  217.35  219.25  216.45  212.95  219.15  224.4   221.45  219.65  214.55  215.75     270.35  272.55  270.95  275.0   272.15  272.95  267.5   264.15  260.35  263.2   260.8   262.2   264.65\n 218.4   216.7   211.9     0.0   220.05  218.5   213.2   215.35  225.85  226.7   220.15  218.7   218.6   216.1      266.85  265.75  266.0   265.8   264.7   265.25  259.7   260.9   260.25  258.6   259.6   262.75  262.0\n 221.95  218.5   217.25  212.7     0.0   221.6   220.15  223.75  226.15  224.0   219.45  220.2   214.35  219.3      264.55  267.0   262.6   262.35  264.2   262.2   262.2   263.25  262.4   262.35  264.3   263.7   262.55\n 219.85  212.5   214.6   216.25  218.75    0.0   221.5   221.45  222.6   223.8   227.35  222.8   217.95  221.55  …  265.75  267.95  263.8   264.5   265.4   262.95  265.7   264.55  261.9   263.7   265.25  259.95  261.35\n 219.15  214.0   214.65  217.8   218.85  217.9     0.0   217.15  227.75  225.6   224.05  217.4   216.8   215.15     266.85  269.95  267.85  264.1   262.55  266.15  267.6   267.1   266.25  263.75  260.95  264.4   267.9\n   ⋮                                       ⋮                                       ⋮                             ⋱                            ⋮                                       ⋮\n 269.75  265.85  263.4   265.65  265.0   266.8   265.8   264.15  261.35  258.3   262.65  264.45  265.5   268.05     216.55  221.35  219.5   221.05  220.1   211.45    0.0   219.05  219.45  214.95  213.8   212.75  214.9\n 267.95  265.7   262.2   262.75  262.0   266.35  264.1   260.45  257.4   264.05  268.05  259.85  264.6   265.4      218.6   225.85  226.8   219.3   220.75  215.7   215.95    0.0   221.05  218.35  214.5   214.2   217.3\n 265.65  262.7   263.2   261.8   261.7   260.8   260.95  257.55  259.15  262.05  264.95  263.1   259.55  259.75  …  221.15  223.75  222.8   226.45  226.25  221.05  221.8   219.6     0.0   215.2   216.55  220.45  222.2\n 264.4   263.0   265.85  263.6   265.35  257.25  254.2   258.5   261.6   259.95  259.45  262.3   262.65  259.25     219.0   217.95  218.6   223.2   220.75  215.1   215.2   218.25  216.35    0.0   215.75  216.8   220.15\n 258.75  262.2   264.2   262.55  262.4   262.6   259.05  258.65  257.5   259.4   265.45  260.1   260.2   261.6      217.4   220.85  219.15  218.05  214.5   214.15  215.8   224.5   217.2   217.35    0.0   218.75  222.8\n 264.5   263.35  257.0   262.9   258.65  264.95  266.05  260.75  259.15  264.8   263.95  265.5   267.3   265.35     221.95  222.65  224.25  221.05  220.95  216.5   220.25  220.5   217.2   218.5   218.05    0.0   223.1\n 266.6   266.35  262.65  262.2   264.45  267.2   266.8   264.25  263.75  262.75  264.5   266.55  267.4   271.6      223.9   226.0   225.6   228.65  225.3   219.85  218.25  220.55  220.75  217.1   220.2   225.15    0.0","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"Of course, it is easier to make sense of the result if we visualize it. Here, we use Plots.jl's heatmap function.","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"using Plots\nheatmap(latencies; c = :viridis, frame=:box)","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"(Image: core2core.png)","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"The two sockets / CPUs of the system with 20 cores each are clearly visible since the inter-core latency of cores on different sockets is, expectedly, higher than the same for cores sitting on the same socket / in the same CPU. Note that due to fluctuations in our imperfect benchmark the result is not precisely symmetric (which, of course, it should be in theory).","category":"page"}]
}
