var documenterSearchIndex = {"docs":
[{"location":"examples/ex_affinity/#exaffinitymask","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"","category":"section"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"In scenarios where the Julia process has a specific affinity mask, e.g. when running under taskset, numactl, or (perhaps) SLURM, you may want to pin your Julia threads in accordance with this affinity mask. To that end, we provide pinthreads(:affinitymask), which pins Julia threads to non-masked CPU-threads (in order, hyperthreads are only used if necessary).","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"For the demonstration below, we consider the following Julia script:","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"$ cat check.jl \nusing ThreadPinning\nif length(ARGS) > 0 && ARGS[1] == \"pin\"\n    pinthreads(:affinitymask)\nend\nprintln(getcpuids())\nprintln(\"no double occupancies: \", length(unique(getcpuids())) == length(getcpuids()))\nprintln(\"in order: \", issorted(getcpuids()))","category":"page"},{"location":"examples/ex_affinity/#tasksetheading","page":"Process Affinity Mask","title":"taskset","text":"","category":"section"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"Let's use taskset --cpu-list to set the affinity of the Julia process.","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"$ taskset --cpu-list 0-24 julia --project -t 25 check.jl\n[13, 13, 4, 5, 6, 7, 8, 11, 15, 14, 12, 16, 18, 19, 0, 10, 3, 9, 24, 2, 17, 20, 1, 21, 21]\nno double occupancies: false\nin order: false","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"Note that","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"some Julia threads may run on the same CPU-thread(!) (which is almost certainly not desired), and\nthe order of the Julia thread to CPU-thread mapping is arbitrary (and non-deterministic).","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"We can remedy both points with pinthreads(:affinitymask):","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"$ taskset --cpu-list 0-24 julia --project -t 25 check.jl pin\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nno double occupancies: true\nin order: true","category":"page"},{"location":"examples/ex_affinity/#numactl","page":"Process Affinity Mask","title":"numactl","text":"","category":"section"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"The same comments as made for taskset above also apply to numactl --physcpubind. Without pinthreads(:affinitymask):","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"$ numactl --physcpubind=0-24 julia --project -t 25 check.jl \n[6, 10, 7, 13, 14, 15, 8, 16, 19, 0, 5, 2, 3, 4, 18, 1, 9, 17, 20, 20, 12, 20, 10, 20, 11]\nno double occupancies: false\nin order: false","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"With pinthreads(:affinitymask):","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"$ numactl --physcpubind=0-24 julia --project -t 25 check.jl pin\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nno double occupancies: true\nin order: true","category":"page"},{"location":"examples/ex_affinity/#SLURM","page":"Process Affinity Mask","title":"SLURM","text":"","category":"section"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"note: Note\nSLURM settings vary a lot between clusters, in particular affinity related settings. In the following, we visualize the affinity mask set by SLURM at the top of the output files (B means \"this CPU can be used\" whereas - indicates \"this CPU can't be used\" and vertical lines indicate different domains.). Be wary that the same job scripts might not set affinity masks on your cluster!","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"$ cat slurm_basic.jl \n#!/usr/bin/env sh\n#SBATCH -N 1\n#SBATCH -n 1\n#SBATCH --cpus-per-task 25\n#SBATCH -o sl_%j.out\n#SBATCH -A pc2-mitarbeiter\n#SBATCH -p all\n#SBATCH -t 00:02:00\n\nsrun -n 1 julia --project -t 25 check.jl ","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"Without pinthreads(:affinitymask):","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"$ cat sl_2374255.out \ncpu-bind=MASK - cn-0181, task  0  0 [1410285]: mask |BBBBBBBBBBBBBBBBBBBB||||BBBBB---------------|  set\ncpu-bind=MASK - cn-0181, task  0  0 [1410316]: mask |BBBBBBBBBBBBBBBBBBBB||||BBBBB---------------|  set\n[11, 16, 17, 2, 15, 18, 19, 13, 3, 4, 5, 6, 7, 10, 9, 8, 14, 11, 20, 0, 12, 13, 4, 2, 1]\nno double occupancies: false\nin order: false","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"Note that","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"some Julia threads may run on the same CPU-thread(!) (which is almost certainly not desired), and\nthe order of the Julia thread to CPU-thread mapping is arbitrary (and non-deterministic).","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"We can remedy both points with pinthreads(:affinitymask):","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"$ cat sl_2374256.out \ncpu-bind=MASK - cn-0197, task  0  0 [1507377]: mask |BBBBBBBBBBBBBBBBBBBB||||BBBBB---------------|  set\ncpu-bind=MASK - cn-0197, task  0  0 [1507410]: mask |BBBBBBBBBBBBBBBBBBBB||||BBBBB---------------|  set\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nno double occupancies: true\nin order: true","category":"page"},{"location":"examples/ex_affinity/#Supplement:-tauto-(Julia-1.9)","page":"Process Affinity Mask","title":"Supplement: -tauto (Julia >= 1.9)","text":"","category":"section"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"For Julia >= 1.9 you can use -tauto to automatically set the number of Julia threads such that it matches the external affinity mask (relevant PR). This is particularly useful when using SLURM, but, for simplicity, we can also showcase it with taskset:","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"$ taskset --cpu-list 0-24 julia +1.9 -tauto --project check.jl pin\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nno double occupancies: true\nin order: true","category":"page"},{"location":"examples/ex_affinity/","page":"Process Affinity Mask","title":"Process Affinity Mask","text":"$ taskset --cpu-list 0-11 julia +1.9 -tauto --project check.jl pin\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\nno double occupancies: true\nin order: true","category":"page"},{"location":"refs/api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"refs/api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"refs/api/","page":"API","title":"API","text":"Pages   = [\"api.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"refs/api/#References-Pinning","page":"API","title":"References - Pinning","text":"","category":"section"},{"location":"refs/api/","page":"API","title":"API","text":"Modules = [ThreadPinning]\nPages   = [\"pinning.jl\", \"mpi.jl\"]","category":"page"},{"location":"refs/api/#ThreadPinning.openblas_pinthread","page":"API","title":"ThreadPinning.openblas_pinthread","text":"openblas_pinthread(cpuid; threadid)\n\nPin the OpenBLAS thread with the given threadid to the given CPU-thread (cpuid).\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.openblas_pinthreads","page":"API","title":"ThreadPinning.openblas_pinthreads","text":"openblas_pinthreads(cpuids; nthreads = BLAS.get_num_threads())\n\nPin the OpenBLAS threads to the given CPU IDs. The optional keyword argument nthreads serves as a cutoff.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.openblas_setaffinity","page":"API","title":"ThreadPinning.openblas_setaffinity","text":"openblas_setaffinity(mask; threadid)\n\nSet the affinity of the OpenBLAS thread with the given threadid to the given mask.\n\nThe input mask should be one of the following:\n\na BitArray to indicate the mask directly\na vector of cpuids (in which case the mask will be constructed automatically)\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.openblas_setaffinity_cpuids","page":"API","title":"ThreadPinning.openblas_setaffinity_cpuids","text":"Set the affinity of the OpenBLAS thread to the given CPU-threads.\n\nExamples:\n\nopenblas_setaffinity_cpuids(socket(1)) # set the affinity to the first socket\nopenblas_setaffinity_cpuids(numa(2)) # set the affinity to the second NUMA domain\nopenblas_setaffinity_cpuids(socket(1, 1:3)) # set the affinity to the first three cores in the first NUMA domain\nopenblas_setaffinity_cpuids([1,3,5]) # set the affinity to the CPU-threads with the IDs 1, 3, and 5.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.openblas_unpinthread","page":"API","title":"ThreadPinning.openblas_unpinthread","text":"openblas_unpinthread(; threadid)\n\nUnpins the OpenBLAS thread with the given threadid by setting its affinity mask to all unity. Afterwards, the OS is free to move the OpenBLAS thread from one CPU thread to another.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.openblas_unpinthreads","page":"API","title":"ThreadPinning.openblas_unpinthreads","text":"openblas_unpinthreads(; threadpool = :default)\n\nUnpins all OpenBLAS threads by setting their affinity masks all unity. Afterwards, the OS is free to move any OpenBLAS thread from one CPU thread to another.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.pinthread","page":"API","title":"ThreadPinning.pinthread","text":"pinthread(cpuid::Integer; threadid = Threads.threadid())\n\nPin the a Julia thread to the given CPU-thread.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.pinthreads","page":"API","title":"ThreadPinning.pinthreads","text":"pinthreads(cpuids;\n    nthreads   = nothing,\n    force      = true,\n    warn       = is_first_pin_attempt(),\n    threadpool = :default\n)\n\nPin Julia threads to an explicit or implicit list of CPU IDs. The latter can be specified in three ways:\n\nby passing one of several predefined symbols (e.g. pinthreads(:cores) or pinthreads(:sockets)),\nby providing a logical specification via helper functions (e.g. pinthreads(numa(2, 1:4))),\nexplicitly (e.g. 0:3 or [0,12,4]).\n\nSee ??pinthreads for more information on these variants and keyword arguments.\n\nKeyword arguments\n\nIf set, the keyword argument nthreads serves as a cutoff, that is, the first min(length(cpuids), nthreads) Julia threads will get pinned.\n\nThe keyword argument threadpool can be used to indicate the pool of Julia threads that should be considered. Supported values are :default (default), :interactive, or :all. On Julia >= 1.11, there is also experimental support for :gc.\n\nIf force=false, threads will only get pinned if this is the very first pin attempt (otherwise the call is a no-op). This may be particularly useful for packages that merely want to specify an (overrulable) \"default pinning\".\n\nThe option warn toggles general warnings, such as unwanted interference with BLAS thread settings.\n\nExtended help\n\n1) Predefined Symbols\n\n:cputhreads or :compact: successively pin to all available CPU-threads.\n:cores: spread threads across all available cores, only use hyperthreads if necessary.\n:sockets: spread threads across sockets (round-robin), only use hyperthreads if             necessary. Set compact=true to get compact pinning within each socket.\n:numa: spread threads across NUMA/memory domains (round-robin), only use hyperthreads          if necessary. Set compact=true to get compact pinning within each NUMA/memory          domain.\n:random: pin threads randomly to CPU-threads\n:current: pin threads to the CPU-threads they are currently running on\n:firstn: pin threads to CPU-threads in order according to there OS index.\n:affinitymask: pin threads to different CPU-threads in accordance with the process                  affinity. By default, hyperthreads_last=true.\n\n2) Logical Specification\n\nThe functions node, socket, numa, and core can be used to to specify CPU IDs of/within a certain domain. Moreover, the functions sockets and numas can be used to express a round-robin scatter policy between sockets or NUMA domains, respectively.\n\nExamples (domains):\n\npinthreads(socket(1, 1:3)) # pin to the first 3 cores in the first socket\npinthreads(socket(1, 1:3; compact=true)) # pin to the first 3 CPU-threads in the first socket\npinthreads(numa(2, [2,4,6])) # pin to the second, the fourth, and the sixth cores in the second NUMA/memory domain\npinthreads(node(ncores():-1:1)) # pin threads to cores in reversing order (starting at the end of the node)\npinthreads(sockets()) # scatter threads between sockets, cores before hyperthreads\n\nDifferent domains can be concatenated by providing them in a vector or as separate arguments to pinthreads.\n\nExamples (concatenation):\n\npinthreads([socket(1, 1:3), numa(2, 4:6)])\npinthreads(socket(1, 1:3), numa(2, 4:6))\n\n3) Explicit\n\nSimply provide an AbstractVector{<:Integer} of CPU IDs. The latter are expected to be \"physical\" OS indices (e.g. from hwloc or lscpu) that start at zero!\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.setaffinity","page":"API","title":"ThreadPinning.setaffinity","text":"setaffinity(mask; threadid = Threads.threadid())\n\nSet the affinity of a Julia thread based on the given mask (a vector of ones and zeros).\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.setaffinity_cpuids","page":"API","title":"ThreadPinning.setaffinity_cpuids","text":"Set the affinity of a Julia thread to the given CPU-threads.\n\nExamples:\n\nsetaffinity(socket(1)) # set the affinity to the first socket\nsetaffinity(numa(2)) # set the affinity to the second NUMA domain\nsetaffinity(socket(1, 1:3)) # set the affinity to the first three cores in the first NUMA domain\nsetaffinity([1,3,5]) # set the affinity to the CPU-threads with the IDs 1, 3, and 5.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.unpinthread","page":"API","title":"ThreadPinning.unpinthread","text":"unpinthread(; threadid::Integer = Threads.threadid())\n\nUnpins the given Julia thread by setting the affinity mask to all unity. Afterwards, the OS is free to move the Julia thread from one CPU thread to another.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.unpinthreads","page":"API","title":"ThreadPinning.unpinthreads","text":"unpinthreads(; threadpool::Symbol = :default)\n\nUnpins all Julia threads by setting the affinity mask of all threads to all unity. Afterwards, the OS is free to move any Julia thread from one CPU thread to another.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.with_pinthreads","page":"API","title":"ThreadPinning.with_pinthreads","text":"with_pinthreads(f::F, args...;\n    soft = false,\n    kwargs...\n)\n\nRuns the function f with the specified pinning and restores the previous thread affinities afterwards. Typically to be used in combination with do-syntax.\n\nBy default (soft=false), before the thread affinities are restored, the Julia threads will be pinned to the CPU-threads they were running on previously.\n\nExample\n\njulia> getcpuids()\n4-element Vector{Int64}:\n  7\n 75\n 63\n  4\n\njulia> with_pinthreads(:cores) do\n           getcpuids()\n       end\n4-element Vector{Int64}:\n 0\n 1\n 2\n 3\n\njulia> getcpuids()\n4-element Vector{Int64}:\n  7\n 75\n 63\n  4\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.pinthreads_mpi","page":"API","title":"ThreadPinning.pinthreads_mpi","text":"pinthreads_mpi(symbol, rank, nranks; nthreads_per_rank, compact, kwargs...)\n\nPin MPI ranks, that is, their respective Julia thread(s), to (subsets of) domains (e.g. sockets or memory domains). Specifically, when calling this function on all MPI ranks, the latter will be distributed in a round-robin fashion among the specified domains such that their Julia threads are pinned to non-overlapping ranges of CPU-threads within the domain.\n\nValid options for symbol are :sockets and :numa.\n\nIf compact=false (default), physical cores are occupied before hyperthreads. Otherwise, CPU-cores - with potentially multiple CPU-threads - are filled up one after another (compact pinning).\n\nThe keyword argument nthreads_per_rank (default Threads.nthreads()) can be used to pin only a subset of the available Julia threads per MPI rank.\n\nNote: As per usual for MPI, rank starts at zero.\n\nExample:\n\nusing ThreadPinning\nusing MPI\ncomm = MPI.COMM_WORLD\nnranks = MPI.Comm_size(comm)\nrank = MPI.Comm_rank(comm)\npinthreads_mpi(:sockets, rank, nranks)\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#References-Querying","page":"API","title":"References - Querying","text":"","category":"section"},{"location":"refs/api/","page":"API","title":"API","text":"Modules = [ThreadPinning]\nPages   = [\"querying.jl\", \"threadinfo.jl\"]","category":"page"},{"location":"refs/api/#ThreadPinning.core","page":"API","title":"ThreadPinning.core","text":"Returns the CPU IDs that belong to core i (logical index, starts at 1). Set shuffle=true to randomize.\n\nOptional second argument: Logical indices to select a subset of the CPU-threads.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.cores","page":"API","title":"ThreadPinning.cores","text":"Returns the CPU IDs of the system as obtained by a round-robin scattering between CPU cores. This is the same as nodes(; compact=false). Set shuffle=true to randomize.\n\nOptional first argument: Logical indices to select a subset of the sockets.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.cpuid","page":"API","title":"ThreadPinning.cpuid","text":"Returns the CPU ID (\"physical\" OS index) that corresponds to the given logical index (starts at 1).\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.cpuids","page":"API","title":"ThreadPinning.cpuids","text":"All valid CPU IDs of the system (sorted).\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.getaffinity","page":"API","title":"ThreadPinning.getaffinity","text":"getaffinity(; threadid = Threads.threadid(), cutoff = cpuidlimit())\n\nGet the thread affinity of a Julia thread. Returns the affinity mask as a vector of zeros and ones. By default, the mask is cut off at Sys.CPU_THREADS. This can be tuned via the cutoff keyword argument (nothing means no cutoff).\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.getcpuid","page":"API","title":"ThreadPinning.getcpuid","text":"getcpuid(; threadid = nothing)\n\nReturns the ID of the CPU thread on which a Julia thread is currently running.\n\nIf threadid=nothing (default), we query the id directly from the calling thread.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.getcpuids","page":"API","title":"ThreadPinning.getcpuids","text":"getcpuids(; threadpool = :default)\n\nReturns the IDs of the CPU-threads on which the Julia threads are currently running on.\n\nThe keyword argument threadpool (default: :default) may be used to specify a specific thread pool.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.getnumanode","page":"API","title":"ThreadPinning.getnumanode","text":"getnumanode(; threadid = nothing)\n\nReturns the ID (starting at zero) of the NUMA node corresponding to the CPU thread on which the calling thread is currently running. A threadid may be provided to consider a Julia thread that is different from the calling one.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.getnumanodes","page":"API","title":"ThreadPinning.getnumanodes","text":"getnumanodes(; threadpool = :default)\n\nReturns the IDs (starting at zero) of the NUMA nodes corresponding to the CPU threads on which the Julia threads are currently running.\n\nThe keyword argument threadpool (default: :default) may be used to consider only those Julia threads that belong to a specific thread pool.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.hyperthreading_is_enabled","page":"API","title":"ThreadPinning.hyperthreading_is_enabled","text":"Check whether simultaneous multithreading (SMT) / \"hyperthreading\" is enabled.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.id","page":"API","title":"ThreadPinning.id","text":"Returns the logical index (starts at 1) that corresponds to the given CPU ID (\"physical\" OS index).\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.isefficiencycore","page":"API","title":"ThreadPinning.isefficiencycore","text":"Returns true if the given CPU-thread lies inside of a CPU-core that has the highest power efficiency of all the CPU-cores (i.e. an efficiency value of 1). If there is only a single CPU-core kind, the return value is false for all CPU IDs.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.ishyperthread","page":"API","title":"ThreadPinning.ishyperthread","text":"Check whether the given CPU-thread is a SMT-thread / \"hyperthread\" (i.e. it is not the first CPU-thread in the CPU-core).\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.ispinned","page":"API","title":"ThreadPinning.ispinned","text":"ispinned(; threadid = Threads.threadid())\n\nReturns true if the thread is pinned, that is, if it has an affinity mask that highlights a single CPU-thread.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.ncorekinds","page":"API","title":"ThreadPinning.ncorekinds","text":"Number of different kinds of cores (e.g. efficiency and performance cores).\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.ncores","page":"API","title":"ThreadPinning.ncores","text":"Number of cores (i.e. excluding hyperthreads)\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.ncputhreads","page":"API","title":"ThreadPinning.ncputhreads","text":"Number of CPU-threads\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.nnuma","page":"API","title":"ThreadPinning.nnuma","text":"Number of NUMA nodes\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.node","page":"API","title":"ThreadPinning.node","text":"Returns all CPU IDs of the system/compute node (logical index, starts at 1). By default, an \"cores before hyperthreads\" ordering is used. Set compact=true if you want compact ordering. Set shuffle=true to randomize.\n\nOptional second argument: Logical indices to select a subset of the CPU-threads.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.nsmt","page":"API","title":"ThreadPinning.nsmt","text":"The number of SMT-threads in a core. If this number varies between different cores, the maximum is returned.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.nsockets","page":"API","title":"ThreadPinning.nsockets","text":"Number of CPU-sockets / CPUs\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.numa","page":"API","title":"ThreadPinning.numa","text":"Returns the CPU IDs that belong to the ith NUMA domain (logical index, starts at 1). By default, an \"cores before hyperthreads\" ordering is used. Set compact=true if you want compact ordering. Set shuffle=true to randomize.\n\nOptional second argument: Logical indices to select a subset of the CPU-threads.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.numas","page":"API","title":"ThreadPinning.numas","text":"Returns the CPU IDs of the system as obtained by a round-robin scattering between NUMA domains. Within each NUMA domain, a round-robin ordering among CPU cores is used (\"cores before hyperthreads\"). Provide compact=true to get compact ordering within each NUMA domain. Set shuffle=true to randomize.\n\nOptional first argument: Logical indices to select a subset of the sockets.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.openblas_getaffinity","page":"API","title":"ThreadPinning.openblas_getaffinity","text":"openblas_getaffinity(; threadid, convert = true)\n\nQuery the affinity of the OpenBLAS thread with the given threadid (typically 1:BLAS.get_num_threads()). By default, returns a vector respresenting the mask. If convert=false a Ccpu_set_t is returned instead.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.openblas_getcpuid","page":"API","title":"ThreadPinning.openblas_getcpuid","text":"openblas_getcpuid(; threadid)\n\nGet the id of the CPU thread on which the OpenBLAS thread with the given threadid is running on according to its affinity.\n\nNote: If the OpenBLAS thread has not been pinned before, this function will error because the affinity mask highlights more than a single CPU thread by default.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.openblas_getcpuids","page":"API","title":"ThreadPinning.openblas_getcpuids","text":"openblas_getcpuids()\n\nGet the ids of the CPU threads on which the OpenBLAS threads are running on according to their affinity. See openblas_getcpuid for more information.\"\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.openblas_ispinned","page":"API","title":"ThreadPinning.openblas_ispinned","text":"openblas_ispinned(; threadid)\n\nCheck if the OpenBLAS thread is pinned to a single CPU thread.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.openblas_printaffinities","page":"API","title":"ThreadPinning.openblas_printaffinities","text":"Print the affinities of all OpenBLAS threads.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.openblas_printaffinity","page":"API","title":"ThreadPinning.openblas_printaffinity","text":"openblas_printaffinity(; threadid)\n\nPrint the affinity of an OpenBLAS thread.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.printaffinities","page":"API","title":"ThreadPinning.printaffinities","text":"printaffinities(; threadpool = :default, kwargs...)\n\nPrint the affinity masks of all Julia threads. See printaffinity for options.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.printaffinity","page":"API","title":"ThreadPinning.printaffinity","text":"printaffinity(; threadid::Integer = Threads.threadid())\n\nPrint the affinity mask of the Julia thread.\n\nThe keyword argument groupby may be used to change how CPU-threads are grouped visually. It defaults to groupby=:socket. Other valid values are :numa and :core.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.socket","page":"API","title":"ThreadPinning.socket","text":"Returns the CPU IDs that belong to the ith CPU/socket (logical index, starts at 1). By default, an \"cores before hyperthreads\" ordering is used. Set compact=true if you want compact ordering. Set shuffle=true to randomize.\n\nOptional second argument: Logical indices to select a subset of the CPU-threads.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.sockets","page":"API","title":"ThreadPinning.sockets","text":"Returns the CPU IDs of the system as obtained by a round-robin scattering between sockets. By default, within each socket, a round-robin ordering among CPU cores is used (\"cores before hyperthreads\"). Provide compact=true to get compact ordering within each socket. Set shuffle=true to randomize.\n\nOptional first argument: Logical indices to select a subset of the sockets.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.visualize_affinity","page":"API","title":"ThreadPinning.visualize_affinity","text":"Visualize the affinity mask of a Julia thread. Many of the keyword options of threadinfo work here as well.\n\n\n\n\n\n","category":"function"},{"location":"refs/api/#ThreadPinning.threadinfo","page":"API","title":"ThreadPinning.threadinfo","text":"threadinfo(;\n    groupby = :sockets,\n    threadpool = :default,\n    blas = false,\n    slurm = false,\n    hints = false,\n    compact = true,\n    hyperthreads = SysInfo.hyperthreading_is_enabled(),\n    efficiency = SysInfo.ncorekinds() > 1,\n    masks = false,\n    coregaps = false,\n    logical = false,\n    color = true,\n    blocksize = choose_blocksize()\n)\n\nPrint information about Julia threads, e.g. on which CPU-threads (i.e. cores if hyperthreading is disabled) they are running.\n\nKeyword arguments\n\ngroupby: Options are :sockets, :numa, :cores, or :none.\nthreadpool: Only consider Julia threads in the given thread pool.                                 Supported values are :default, :interactive, and                                 :all.\nblas: Visualize BLAS threads instead of Julia threads.\nslurm: Only show the part of the system that is covered by the active SLURM allocation.\nhints: Give some hints about how to improve the threading related settings.\ncompact: Toggle between compact and \"cores before hyperthreads\" ordering.\nhyperthreads: If true, we (try to) highlight CPU-threads that aren't the first threads within a CPU-core.\nefficiency: If true, we highlight (underline) CPU-threads that belong to efficiency cores.\nmasks: Show the affinity masks of all Julia threads.\ncoregaps: Put an extra space (\"gap\") between different CPU-cores, when printing.\nlogical: Toggle between logical and \"physical\" CPU-thread indices.\ncolor: Toggle between colored and black-and-white output.\nblocksize: Wrap to a new line after blocksize many CPU-threads.  May also be set to :numa in which case the line break will occur after each numa domain.\n\n\n\n\n\n","category":"function"},{"location":"examples/ex_pinning_julia_threads/#Pinning-Julia-Threads","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"The most important functions are pinthreads and threadinfo. The former allows you to pin threads. The latter visualizes the current thread-processor mapping and the system topology. Please check out the comprehensive documentation of these functions for detailed information. ","category":"page"},{"location":"examples/ex_pinning_julia_threads/#Typical-usage","page":"Pinning Julia Threads","title":"Typical usage","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/#pinthreads","page":"Pinning Julia Threads","title":"pinthreads","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Pinning your threads is as simple as putting the following at the top of your Julia code:","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"using ThreadPinning\npinthreads(:cores)","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"This will successively pin all Julia threads to CPU-cores in logical order, avoiding hyperthreads if possible. Of course, you can replace :cores by all the options supported by pinthreads. Conceptually, there are three different formats to specify your desired thread-processor mapping:","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"explicit lists of CPU IDs (e.g. 0:3 or [0,12,4]),\npredefined symbols (e.g. :cores or :sockets),\nlogical specification of domains via helper functions (e.g. node and socket).","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"For example, instead of pinthreads(:cores) above, you could write pinthreads(1:2:10) or pinthreads(socket(1,1:3), numa(2,2:5)). Again, see pinthreads for more information.","category":"page"},{"location":"examples/ex_pinning_julia_threads/#threadinfo","page":"Pinning Julia Threads","title":"threadinfo","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"To check and visualize the current pinning you can use threadinfo to get something like this.","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"(Image: threadinfo_ht_long.png)","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"As you can see, this image is taken on a dual-socket system (indicated by the two | .... | sections) where each CPU has 20 CPU-cores and Julia has been started with 40 threads. Hyperthreading is enabled - the greyed out numbers indicate hyperthreads/SMT-threads - with two CPU-threads per core.","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Note that threadinfo has a few keyword arguments that let you change or tune the output. The most important ones are probably groupby and color. The former allows you to switch from socket to, say, NUMA/memory domain visualization (groupby=:numa). The latter allows you to switch to non-colored output (see below).","category":"page"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"julia> using ThreadPinning\n\njulia> threadinfo(; color=false)\n\n| 0,1,_,3,4,_,_,7,8,_,10,_,_,_,_,_,\n  16,17,_,_,40,_,42,_,_,_,_,47,48,49,50,51,\n  _,_,54,_,_,57,58,_ |\n| _,21,22,23,_,_,_,_,28,29,30,_,32,33,_,35,\n  _,_,38,39,60,61,62,63,64,65,_,_,68,_,_,_,\n  72,73,74,_,_,_,_,_ |\n\n# = Julia thread, # = HT, # = Julia thread on HT, | = Socket seperator\n\nJulia threads: 40\n├ Occupied CPU-threads: 40\n└ Mapping (Thread => CPUID): 1 => 63, 2 => 64, 3 => 17, 4 => 68, 5 => 4, ...\n\n\njulia> pinthreads(:cores)\n\njulia> threadinfo(; color=false)\n\n| 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\n  16,17,18,19,_,_,_,_,_,_,_,_,_,_,_,_,\n  _,_,_,_,_,_,_,_ |\n| 20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,\n  36,37,38,39,_,_,_,_,_,_,_,_,_,_,_,_,\n  _,_,_,_,_,_,_,_ |\n\n# = Julia thread, # = HT, # = Julia thread on HT, | = Socket seperator\n\nJulia threads: 40\n├ Occupied CPU-threads: 40\n└ Mapping (Thread => CPUID): 1 => 0, 2 => 1, 3 => 2, 4 => 3, 5 => 4, ...\n\n\njulia> pinthreads(:cputhreads)\n\njulia> threadinfo(; color=false)\n\n| 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\n  16,17,18,19,40,41,42,43,44,45,46,47,48,49,50,51,\n  52,53,54,55,56,57,58,59 |\n| _,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,\n  _,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,\n  _,_,_,_,_,_,_,_ |\n\n# = Julia thread, # = HT, # = Julia thread on HT, | = Socket seperator\n\nJulia threads: 40\n├ Occupied CPU-threads: 40\n└ Mapping (Thread => CPUID): 1 => 0, 2 => 40, 3 => 1, 4 => 41, 5 => 2, ...","category":"page"},{"location":"examples/ex_pinning_julia_threads/#Default-pinning-(for-packages)","page":"Pinning Julia Threads","title":"Default pinning (for packages)","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"If you're developing a package you may want to provide a reasonable default pinning. If you would naively use pinthreads for this, you would enforce a certain pinning irrespective of what the user might have specified manually. This is because pinthreads has the highest precedence. To lower the latter you can set force=false in your pinthreads call, e.g. pinthreads(:cores; force=false). This way, a user can overwrite your default pinning (:cores in this example), e.g. by calling pinthreads manually before running your package code.","category":"page"},{"location":"examples/ex_pinning_julia_threads/#Unpinning","page":"Pinning Julia Threads","title":"Unpinning","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"We provide functions unpinthread(threadid) and unpinthreads() to unpin a specific or all Julia threads, respectively. This is realized by setting the thread affinity mask to all ones. While technically not really unpinning threads, you might also want to consider using pinthreads(:random) for \"fake unpinning\" in benchmarks as it does randomize the thread placing but keeps it fixed to reduce measurement fluctuations.","category":"page"},{"location":"examples/ex_pinning_julia_threads/#likwid-pin-compatible-input","page":"Pinning Julia Threads","title":"likwid-pin-compatible input","text":"","category":"section"},{"location":"examples/ex_pinning_julia_threads/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Separate from pinthreads, used and described above, we offer pinthreads_likwidpin which, ideally, should handle all inputs that are supported by the -c option of likwid-pin (e.g. S0:1-3@S1:2,4,5 or E:N:4:2:4). If you encounter an input that doesn't work as expected, please file an issue.","category":"page"},{"location":"refs/blaslapack/#BLAS/LAPACK","page":"BLAS/LAPACK","title":"BLAS/LAPACK","text":"","category":"section"},{"location":"refs/blaslapack/","page":"BLAS/LAPACK","title":"BLAS/LAPACK","text":"warning: Warning\nThis section isn't part of the official API. Things might change at any point without further notice.","category":"page"},{"location":"refs/blaslapack/#Index","page":"BLAS/LAPACK","title":"Index","text":"","category":"section"},{"location":"refs/blaslapack/","page":"BLAS/LAPACK","title":"BLAS/LAPACK","text":"Pages   = [\"blaslapack.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"refs/blaslapack/#References-Intel-MKL","page":"BLAS/LAPACK","title":"References - Intel MKL","text":"","category":"section"},{"location":"refs/blaslapack/","page":"BLAS/LAPACK","title":"BLAS/LAPACK","text":"Modules = [ThreadPinning, ThreadPinning.MKL]\nPages   = [\"mkl.jl\"]","category":"page"},{"location":"refs/blaslapack/#ThreadPinning.MKL.mkl_fullpath-Tuple{}","page":"BLAS/LAPACK","title":"ThreadPinning.MKL.mkl_fullpath","text":"Returns the full path to the libmkl_rt library if the latter is loaded. Will try to locate the library and, if successfull, will cache the result. Throws an error otherwise.\n\nTo force an update of the cache, provide force_update=true.\n\n\n\n\n\n","category":"method"},{"location":"refs/blaslapack/#ThreadPinning.MKL.mkl_get_dynamic-Tuple{}","page":"BLAS/LAPACK","title":"ThreadPinning.MKL.mkl_get_dynamic","text":"mkl_get_dynamic()\n\nWrapper around the MKL function mkl_get_dynamic.\n\n\n\n\n\n","category":"method"},{"location":"refs/blaslapack/#ThreadPinning.MKL.mkl_is_loaded-Tuple{}","page":"BLAS/LAPACK","title":"ThreadPinning.MKL.mkl_is_loaded","text":"Check whether Intel MKL is currently loaded via libblastrampoline (Julia >= 1.7) or is available in Libdl.dllist() (Julia 1.6).\n\n\n\n\n\n","category":"method"},{"location":"refs/blaslapack/#ThreadPinning.MKL.mkl_set_dynamic-Tuple{Integer}","page":"BLAS/LAPACK","title":"ThreadPinning.MKL.mkl_set_dynamic","text":"mkl_set_dynamic(flag::Integer)\n\nWrapper around the MKL function mkl_set_dynamic.\n\n\n\n\n\n","category":"method"},{"location":"refs/libX/#LibX","page":"LibX","title":"LibX","text":"","category":"section"},{"location":"refs/libX/","page":"LibX","title":"LibX","text":"warning: Warning\nThis section isn't part of the official API. Things might change at any point without further notice.","category":"page"},{"location":"refs/libX/","page":"LibX","title":"LibX","text":"Wrappers around some functionality provided by libc, libpthread, and libuv.","category":"page"},{"location":"refs/libX/#Index","page":"LibX","title":"Index","text":"","category":"section"},{"location":"refs/libX/","page":"LibX","title":"LibX","text":"Pages   = [\"libX.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"refs/libX/#References","page":"LibX","title":"References","text":"","category":"section"},{"location":"refs/libX/","page":"LibX","title":"LibX","text":"Modules = [ThreadPinning]\nPages   = [\"libuv.jl\", \"libc.jl\", \"libpthread.jl\"]","category":"page"},{"location":"refs/latency/#Latency","page":"Latency","title":"Latency","text":"","category":"section"},{"location":"refs/latency/","page":"Latency","title":"Latency","text":"warning: Warning\nThis section isn't part of the official API. Things might change at any point without further notice.","category":"page"},{"location":"refs/latency/#Index","page":"Latency","title":"Index","text":"","category":"section"},{"location":"refs/latency/","page":"Latency","title":"Latency","text":"Pages   = [\"latency.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"refs/latency/#References","page":"Latency","title":"References","text":"","category":"section"},{"location":"refs/latency/","page":"Latency","title":"Latency","text":"Modules = [ThreadPinning]\nPages   = [\"latency.jl\"]","category":"page"},{"location":"explanations/linux/#linux","page":"Why is Only Linux Supported?","title":"Why is Only Linux Supported?","text":"","category":"section"},{"location":"explanations/linux/","page":"Why is Only Linux Supported?","title":"Why is Only Linux Supported?","text":"For ThreadPinning.jl to fully work, the operating system must support querying and setting the affinity of Julia threads (pthreads). This is readily possible on Linux but less so or more complicated on Windows and macOS. See below for more information.","category":"page"},{"location":"explanations/linux/#Linux","page":"Why is Only Linux Supported?","title":"Linux","text":"","category":"section"},{"location":"explanations/linux/","page":"Why is Only Linux Supported?","title":"Why is Only Linux Supported?","text":"We use libcs sched_getcpu to query the ID of the CPU-Thread that is currently running a given Julia thread. For pinning, we use uv_thread_setaffinity provided by libuv. For the corresponding Julia wrappers of these libraries, see LibX.","category":"page"},{"location":"explanations/linux/#Windows","page":"Why is Only Linux Supported?","title":"Windows","text":"","category":"section"},{"location":"explanations/linux/","page":"Why is Only Linux Supported?","title":"Why is Only Linux Supported?","text":"I neither have much knowledge about Windows APIs nor proper access to Windows machines. Nonetheless, I've made an initial attempt to add partial Windows support in this PR. If you're eager to have Windows fully supported, please take matters into your own hand. I'm happy to offer help and review a PR from you.","category":"page"},{"location":"explanations/linux/#macOS","page":"Why is Only Linux Supported?","title":"macOS","text":"","category":"section"},{"location":"explanations/linux/","page":"Why is Only Linux Supported?","title":"Why is Only Linux Supported?","text":"Unfortunately, macOS doesn't support any way to pin threads to specific CPU-threads. It is thus very unlikely that macOS can ever be fully supported.","category":"page"},{"location":"explanations/linux/","page":"Why is Only Linux Supported?","title":"Why is Only Linux Supported?","text":"Having said that, there seems to be a (very?) limited Thread Affinity API for which support might be added. This is unlikely to ever be on my agenda though.","category":"page"},{"location":"refs/utility/#Utility","page":"Utility","title":"Utility","text":"","category":"section"},{"location":"refs/utility/","page":"Utility","title":"Utility","text":"warning: Warning\nThis section isn't part of the official API. Things might change at any point without further notice.","category":"page"},{"location":"refs/utility/#Index","page":"Utility","title":"Index","text":"","category":"section"},{"location":"refs/utility/","page":"Utility","title":"Utility","text":"Pages   = [\"utility.md\"]\nOrder   = [:function, :type, :macro]","category":"page"},{"location":"refs/utility/#References","page":"Utility","title":"References","text":"","category":"section"},{"location":"refs/utility/","page":"Utility","title":"Utility","text":"Modules = [ThreadPinning]\nPages   = [\"utility.jl\"]","category":"page"},{"location":"explanations/why/#why","page":"Why Pin Julia Threads?","title":"Why Pin Julia Threads?","text":"","category":"section"},{"location":"explanations/why/","page":"Why Pin Julia Threads?","title":"Why Pin Julia Threads?","text":"Because","category":"page"},{"location":"explanations/why/","page":"Why Pin Julia Threads?","title":"Why Pin Julia Threads?","text":"it effects performance (MFlops/s), in particular on HPC clusters with multiple NUMA domains\nit allows you to utilize performance counters inside of CPU-cores for hardware-performance monitoring\nit makes performance benchmarks more reliable (i.e. less random/noisy)\n...","category":"page"},{"location":"examples/ex_mpi/#MPI","page":"MPI","title":"MPI","text":"","category":"section"},{"location":"examples/ex_mpi/#SLURM","page":"MPI","title":"SLURM","text":"","category":"section"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"In this section, we'll focus on MPI applications that run under SLURM (or a similar job scheduler). On most systems, the latter sets the affinity mask of the Julia processes (MPI ranks) based on the options set by the user (e.g. via #SBATCH). Consequently, one has to do little to nothing on the Julia side to achieve the desired pinning pattern.","category":"page"},{"location":"examples/ex_mpi/#MPI-only","page":"MPI","title":"MPI only","text":"","category":"section"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"If your MPI-parallel application is single threaded (i.e. one Julia thread per MPI rank), you likely don't have to do anything on the Julia side to pin the MPI ranks. Instead, you can just use the SLURM options.","category":"page"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"Multinode example, 1 MPI rank per socket:","category":"page"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"#!/usr/bin/env sh\n#SBATCH -N 2 # two nodes\n#SBATCH -n 4 # four MPI ranks in total\n#SBATCH --ntasks-per-socket 1 # one MPI rank per socket\n#SBATCH -o sl_mpi_multinode_%j.out\n#SBATCH -A pc2-mitarbeiter\n#SBATCH -p all\n#SBATCH -t 00:02:00\n#=\nml lang JuliaHPC # load Julia module (system specific!)\nsrun -n 4 julia --project -t 1 $(scontrol show job $SLURM_JOBID | awk -F= '/Command=/{print $2}')\nexit\n# =#\nusing MPI\nusing ThreadPinning\n\nMPI.Init()\nnranks = MPI.Comm_size(MPI.COMM_WORLD)\nrank = MPI.Comm_rank(MPI.COMM_WORLD)\nMPI.Barrier()\nsleep(2*rank)\nprintln(\"Rank $rank:\")\nprintln(\"\\tHost: \", gethostname())\nprintln(\"\\tCPUs: \", getcpuids())\nprint_affinity_masks()","category":"page"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"Output (manually cleaned up a bit):","category":"page"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"Rank 0:\n    Host: n2fpga19\n    CPUs: [0]\n1:   |1000000000000000000000000000000000000000000000000000000000000000|0000000000000000000000000000000000000000000000000000000000000000|\n\nRank 1:\n    Host: n2fpga19\n    CPUs: [64]\n1:   |0000000000000000000000000000000000000000000000000000000000000000|1000000000000000000000000000000000000000000000000000000000000000|\n\nRank 2:\n    Host: n2fpga33\n    CPUs: [0]\n1:   |1000000000000000000000000000000000000000000000000000000000000000|0000000000000000000000000000000000000000000000000000000000000000|\n\nRank 3:\n    Host: n2fpga33\n    CPUs: [64]\n1:   |0000000000000000000000000000000000000000000000000000000000000000|1000000000000000000000000000000000000000000000000000000000000000|","category":"page"},{"location":"examples/ex_mpi/#Hybrid:-MPI-Threads","page":"MPI","title":"Hybrid: MPI + Threads","text":"","category":"section"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"If your MPI-parallel application is multithreaded (i.e. multiple Julia threads per MPI rank), you can use pinthreads(:affinitymask) to pin Julia threads of each MPI rank according to the affinity mask set by SLURM (according to the user-specified options). If you don't use pinthreads(:affinitymask), the Julia threads are only bound to a range of CPU-threads, they can migrate, and they can also overlap (occupy the same CPU-thread). See Process Affinity Mask for more information.","category":"page"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"Multinode example, 1 MPI rank per socket, 25 threads per rank:","category":"page"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"#!/usr/bin/env sh\n#SBATCH -N 2\n#SBATCH -n 4\n#SBATCH --ntasks-per-socket 1\n#SBATCH --cpus-per-task 25\n#SBATCH -o sl_hybrid_multinode_affinitymask_%j.out\n#SBATCH -A pc2-mitarbeiter\n#SBATCH -p all\n#SBATCH -t 00:02:00\n#=\nml lang JuliaHPC\nsrun -n 4 julia --project -t 25 $(scontrol show job $SLURM_JOBID | awk -F= '/Command=/{print $2}')\nexit\n# =#\nusing MPI\nusing ThreadPinning\npinthreads(:affinitymask)\n\nMPI.Init()\nnranks = MPI.Comm_size(MPI.COMM_WORLD)\nrank = MPI.Comm_rank(MPI.COMM_WORLD)\nMPI.Barrier()\nsleep(2*rank)\nprintln(\"Rank $rank:\")\nprintln(\"\\tHost: \", gethostname())\nprintln(\"\\tCPUs: \", getcpuids())","category":"page"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"Output:","category":"page"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"Rank 0:\n    Host: n2cn0853\n    CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nRank 1:\n    Host: n2cn0853\n    CPUs: [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88]\nRank 2:\n    Host: n2cn0854\n    CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nRank 3:\n    Host: n2cn0854\n    CPUs: [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88]","category":"page"},{"location":"examples/ex_mpi/#Manual","page":"MPI","title":"Manual","text":"","category":"section"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"In this section, we describe how you can pin the Julia threads of your MPI ranks manually, that is without any \"help\" from an external affinity mask (e.g. as set by SLURM, see above).","category":"page"},{"location":"examples/ex_mpi/","page":"MPI","title":"MPI","text":"TODO: pinthreads_mpi","category":"page"},{"location":"refs/likwidpin/#Likwid-Pin","page":"Likwid-Pin","title":"Likwid-Pin","text":"","category":"section"},{"location":"refs/likwidpin/#Index","page":"Likwid-Pin","title":"Index","text":"","category":"section"},{"location":"refs/likwidpin/","page":"Likwid-Pin","title":"Likwid-Pin","text":"Pages   = [\"likwidpin.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"refs/likwidpin/#References","page":"Likwid-Pin","title":"References","text":"","category":"section"},{"location":"refs/likwidpin/","page":"Likwid-Pin","title":"Likwid-Pin","text":"Modules = [ThreadPinning]\nPages   = [\"likwid-pin.jl\"]","category":"page"},{"location":"refs/likwidpin/#ThreadPinning.likwidpin_domains","page":"Likwid-Pin","title":"ThreadPinning.likwidpin_domains","text":"likwidpin_domains(; onebased = false)\n\nThe likwid-pin compatible domains that are available for the system.\n\n\n\n\n\n","category":"function"},{"location":"refs/likwidpin/#ThreadPinning.likwidpin_to_cpuids","page":"Likwid-Pin","title":"ThreadPinning.likwidpin_to_cpuids","text":"likwidpin_to_cpuids(lpstr::AbstractString; onebased = false)\n\nConvert the given likwid-pin compatible string into a CPU ID list. See pinthreads_likwidpin for more information.\n\n\n\n\n\n","category":"function"},{"location":"refs/likwidpin/#ThreadPinning.pinthreads_likwidpin","page":"Likwid-Pin","title":"ThreadPinning.pinthreads_likwidpin","text":"pinthreads_likwidpin(str::AbstractString; onebased = false)\n\nPins Julia threads to CPU-threads based on the given likwid-pin compatible string. Checkout the LIKWID documentation for more information.\n\nIf the keyword argument onebased is set to true, logical indices as well as domain indices start at one instead of zero (likwid-pin default). Note, though, that this doesn't affect the explicit pinning mode where \"physical\" CPU IDs always start at zero.\n\nExamples\n\npinthreads_likwidpin(\"S0:0-3\")\npinthreads_likwidpin(\"M1:0,2,4\")\npinthreads_likwidpin(\"S:scatter\")\npinthreads_likwidpin(\"E:N:4:1:2\")\n\n\n\n\n\n","category":"function"},{"location":"examples/ex_blas/#ex_blas","page":"Autochecking BLAS Thread Settings","title":"Autochecking BLAS Thread Settings","text":"","category":"section"},{"location":"examples/ex_blas/","page":"Autochecking BLAS Thread Settings","title":"Autochecking BLAS Thread Settings","text":"If one runs a multithreaded Julia code that, on each thread, performs linear algebra operations (BLAS/LAPACK calls) one can easily run into performance issues due to an oversubscription of cores by Julia and BLAS threads (see here for a more thorough discussion). Fortunately, ThreadPinning.jl provides some (basic) autochecking functionality that highlights potential problems and suggests improvements.","category":"page"},{"location":"examples/ex_blas/","page":"Autochecking BLAS Thread Settings","title":"Autochecking BLAS Thread Settings","text":"Concretely, you can provide the keyword argument blas=true to threadinfo. This will show some of your BLAS settings and will color-indicate whether they are likely to be ok (green) or suboptimal (red). If you also provide hints=true, ThreadPinning.jl will try to provide concrete notes and warnings that (hopefully) help you to tune your settings.","category":"page"},{"location":"examples/ex_blas/#OpenBLAS","page":"Autochecking BLAS Thread Settings","title":"OpenBLAS","text":"","category":"section"},{"location":"examples/ex_blas/","page":"Autochecking BLAS Thread Settings","title":"Autochecking BLAS Thread Settings","text":"(Image: openblas)","category":"page"},{"location":"examples/ex_blas/#Intel-MKL","page":"Autochecking BLAS Thread Settings","title":"Intel MKL","text":"","category":"section"},{"location":"examples/ex_blas/","page":"Autochecking BLAS Thread Settings","title":"Autochecking BLAS Thread Settings","text":"(Image: mkl)","category":"page"},{"location":"explanations/blas/#BLAS","page":"Julia Threads + BLAS Threads","title":"Julia Threads + BLAS Threads","text":"","category":"section"},{"location":"explanations/blas/","page":"Julia Threads + BLAS Threads","title":"Julia Threads + BLAS Threads","text":"This page is concerned with the performance and pinning issues that can occur if you run a multithreaded Julia code that, on each thread, performs linear algebra operations (BLAS/LAPACK calls). In this case, one must ensure that cores aren't oversubscribe due to the two levels of multithreading.","category":"page"},{"location":"explanations/blas/","page":"Julia Threads + BLAS Threads","title":"Julia Threads + BLAS Threads","text":"Relevant discourse threads, see here and here.","category":"page"},{"location":"explanations/blas/#OpenBLAS","page":"Julia Threads + BLAS Threads","title":"OpenBLAS","text":"","category":"section"},{"location":"explanations/blas/","page":"Julia Threads + BLAS Threads","title":"Julia Threads + BLAS Threads","text":"If OPENBLAS_NUM_THREADS=1, OpenBLAS uses the calling Julia thread(s) to run BLAS computations, i.e. it \"reuses\" the Julia thread that runs a computation.\nIf OPENBLAS_NUM_THREADS=N>1, OpenBLAS creates and manages its own pool of BLAS threads (N in total). There is one BLAS thread pool (for all Julia threads).\nJulia default: OPENBLAS_NUM_THREADS=8 (Julia version ≤ 1.8) and OPENBLAS_NUM_THREADS=Sys.CPU_THREADS (Julia version ≥ 1.8).","category":"page"},{"location":"explanations/blas/","page":"Julia Threads + BLAS Threads","title":"Julia Threads + BLAS Threads","text":"When you start Julia in multithreaded mode, i.e. julia -tX or JULIA_NUM_THREADS=X, it is generally recommended to set OPENBLAS_NUM_THREADS=1 or, equivalently, BLAS.set_num_threads(1). Given the behavior above, increasing the number of BLAS threads to N>1 can very easily lead to worse performance, in particular when N<<X! Hence, if you want to or need to deviate from unity, make sure to \"jump\" from OPENBLAS_NUM_THREADS=1 to OPENBLAS_NUM_THREADS=# of cores or similar.","category":"page"},{"location":"explanations/blas/#Intel-MKL","page":"Julia Threads + BLAS Threads","title":"Intel MKL","text":"","category":"section"},{"location":"explanations/blas/","page":"Julia Threads + BLAS Threads","title":"Julia Threads + BLAS Threads","text":"Given MKL_NUM_THREADS=N, MKL starts N BLAS threads per Julia thread that makes a BLAS call.\nDefault: MKL_NUM_THREADS=# of physical cores, i.e. excluding hyperthreads. (Verified experimentally but would be good to find a source for this.)","category":"page"},{"location":"explanations/blas/","page":"Julia Threads + BLAS Threads","title":"Julia Threads + BLAS Threads","text":"When you start Julia in multithreaded mode, i.e. julia -tX or JULIA_NUM_THREADS=X, we recommend to set MKL_NUM_THREADS=(# of cores)/X or, equivalently, BLAS.set_num_threads((# of cores)/X) (after using MKL). Unfortunately, the default is generally suboptimal as soon as you don't run Julia with a single thread. Hence, make sure to tune the settings appropriately.","category":"page"},{"location":"explanations/blas/","page":"Julia Threads + BLAS Threads","title":"Julia Threads + BLAS Threads","text":"Side comment: It is particularly bad / confusing that OpenBLAS and MKL behave very differently for multithreaded Julia.","category":"page"},{"location":"explanations/blas/","page":"Julia Threads + BLAS Threads","title":"Julia Threads + BLAS Threads","text":"warning: Warning\nBe aware that calling an MKL function (for the first time) can spoil the pinning of Julia threads! A concrete example is discussed here. TLDR: You want to make sure that MKL_DYNAMIC=false. Apart from setting the environment variable you can also dynamically call ThreadPinning.MKL.mkl_set_dynamic(0). Note that, by default, ThreadPinning.jl will warn you if you call one of the pinning functions while MKL_DYNAMIC=true.","category":"page"},{"location":"explanations/blas/#threadinfo(;-blastrue,-hintstrue)","page":"Julia Threads + BLAS Threads","title":"threadinfo(; blas=true, hints=true)","text":"","category":"section"},{"location":"explanations/blas/","page":"Julia Threads + BLAS Threads","title":"Julia Threads + BLAS Threads","text":"To automatically detect whether you (potentially) have suboptimal BLAS thread settings, you can provide the keyword arguments blas=true and hints=true to threadinfo. An example can be found here.","category":"page"},{"location":"#ThreadPinning.jl","page":"ThreadPinning","title":"ThreadPinning.jl","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"ThreadPinning.jl allows you to pin Julia threads to specific CPU-threads (i.e. \"hardware threads\" or, equivalently, \"CPU processors\") via functions, environment variables, or Julia preferences. Especially for applications running on HPC clusters, this is often absolutely crucial to achieve optimal performance and/or obtain reliable benchmarks (see Why pin Julia threads?).","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"note: Note\nBe aware that Julia implements task-based multithreading: M user tasks get scheduled onto N Julia threads. While this package allows you to pin Julia threads to CPU-threads,  it is generally not safe to assume that a computation (started with Threads.@spawn or Threads.@threads) will run on or even stay on a certain Julia thread (see this discourse post for more information). If you want this guarantee, you can use ThreadPinning.@spawnat instead.","category":"page"},{"location":"#Installation","page":"ThreadPinning","title":"Installation","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"The package is registered. Hence, you can simply use","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"] add ThreadPinning","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"to add the package to your Julia environment.","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"Note that ThreadPinning.jl, specifically the pinning functionality, only works on Linux. On other operating systems, all pinning calls (e.g. pinthreads) will be no-ops.","category":"page"},{"location":"#Prerequisites","page":"ThreadPinning","title":"Prerequisites","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"To gather information about the hardware topology of the system (e.g. sockets and memory domains), ThreadPinning.jl uses lscpu. The latter must therefore be available (i.e. be on PATH), which should automatically be the case on virtually all linux systems.","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"In the unlikely case that lscpu isn't already installed on your system, here are a few ways to get it","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"install util-linux via your system's package manager or manually from here\ndownload the same as a Julia artifact: util_linux_jll.jl","category":"page"},{"location":"#Autoupdate-setting","page":"ThreadPinning","title":"Autoupdate setting","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"By default, ThreadPinning.jl queries the system topology using lscpu on startup (i.e. at runtime). This is quite costly but is unfortunately necessary since you might have precompiled the package on one machine and use it from another (think e.g. login and compute nodes of a HPC cluster). However, you can tell ThreadPinning.jl to permanently skip this autoupdate at runtime and to always use the system topology that was present at compile time (i.e. when precompiling the package). This is perfectly safe if you don't use the same Julia depot on different machines, in particular if you're a \"standard user\" that uses Julia on a desktop computer or laptop, and can reduce the package load time significantly. To do so, simply call ThreadPinning.Prefs.set_autoupdate(false).","category":"page"},{"location":"#Terminology-in-This-Package","page":"ThreadPinning","title":"Terminology in This Package","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"CPU: Chip that sits in a socket and (almost always) hosts multiple CPU-cores.\nCPU-cores: Physical processor cores of the CPU.\nCPU-threads: Hardware threads (a.k.a. \"virtual cores\") within the CPU-cores.\nCPU ID: Unique ID that identifies a specific CPU-thread. (This is somewhat inconsistent but has been chosen for brevity and backwards-compatibility reasons.)","category":"page"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"If the system supports SMT (\"hyperthreading\"), there are more CPU-threads than CPU-cores (most commonly a factor of two more). Independent of the CPU vendor, we refer to all but the first CPU-threads in a core as hyperthreads (order is taken from lscpu). The latter are highlighted differently in output, see threadinfo().","category":"page"},{"location":"#Noteworthy-Alternatives","page":"ThreadPinning","title":"Noteworthy Alternatives","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"Simply setting JULIA_EXCLUSIVE=1 will pin Julia threads to CPU-threads in \"physical order\" (i.e. as specified by lscpu), which might or might not include hyperthreads.\npinthreads or likwid-pin (CLI tool) from LIKWID.jl\nThis discourse thread discusses issues with alternatives like numactl","category":"page"},{"location":"#Acknowledgements","page":"ThreadPinning","title":"Acknowledgements","text":"","category":"section"},{"location":"","page":"ThreadPinning","title":"ThreadPinning","text":"CI infrastructure is provided by the Paderborn Center for Parallel Computing (PC²)","category":"page"},{"location":"examples/ex_core2core_latency/#Core-to-Core-Latency","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"","category":"section"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"Let's measure the inter-core latencies of one of the compute nodes of Noctua 1 at PC2.","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"using ThreadPinning\nlatencies = ThreadPinning.bench_core2core_latency()","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"40×40 Matrix{Float64}:\n   0.0   217.05  204.85  206.0   203.3   204.95  211.7   205.2   209.5   210.1   209.65  209.3   198.7   194.95  …  271.1   267.5   265.0   260.85  266.9   267.15  265.8   266.7   265.55  258.85  262.1   263.95  269.4\n 215.55    0.0   214.65  215.15  219.8   222.1   219.55  217.1   223.1   224.7   220.25  219.45  213.2   214.6      266.6   269.45  269.85  270.6   271.25  271.1   267.45  265.65  263.15  259.85  260.85  263.2   267.45\n 224.2   214.75    0.0   216.05  217.35  219.25  216.45  212.95  219.15  224.4   221.45  219.65  214.55  215.75     270.35  272.55  270.95  275.0   272.15  272.95  267.5   264.15  260.35  263.2   260.8   262.2   264.65\n 218.4   216.7   211.9     0.0   220.05  218.5   213.2   215.35  225.85  226.7   220.15  218.7   218.6   216.1      266.85  265.75  266.0   265.8   264.7   265.25  259.7   260.9   260.25  258.6   259.6   262.75  262.0\n 221.95  218.5   217.25  212.7     0.0   221.6   220.15  223.75  226.15  224.0   219.45  220.2   214.35  219.3      264.55  267.0   262.6   262.35  264.2   262.2   262.2   263.25  262.4   262.35  264.3   263.7   262.55\n 219.85  212.5   214.6   216.25  218.75    0.0   221.5   221.45  222.6   223.8   227.35  222.8   217.95  221.55  …  265.75  267.95  263.8   264.5   265.4   262.95  265.7   264.55  261.9   263.7   265.25  259.95  261.35\n 219.15  214.0   214.65  217.8   218.85  217.9     0.0   217.15  227.75  225.6   224.05  217.4   216.8   215.15     266.85  269.95  267.85  264.1   262.55  266.15  267.6   267.1   266.25  263.75  260.95  264.4   267.9\n   ⋮                                       ⋮                                       ⋮                             ⋱                            ⋮                                       ⋮\n 269.75  265.85  263.4   265.65  265.0   266.8   265.8   264.15  261.35  258.3   262.65  264.45  265.5   268.05     216.55  221.35  219.5   221.05  220.1   211.45    0.0   219.05  219.45  214.95  213.8   212.75  214.9\n 267.95  265.7   262.2   262.75  262.0   266.35  264.1   260.45  257.4   264.05  268.05  259.85  264.6   265.4      218.6   225.85  226.8   219.3   220.75  215.7   215.95    0.0   221.05  218.35  214.5   214.2   217.3\n 265.65  262.7   263.2   261.8   261.7   260.8   260.95  257.55  259.15  262.05  264.95  263.1   259.55  259.75  …  221.15  223.75  222.8   226.45  226.25  221.05  221.8   219.6     0.0   215.2   216.55  220.45  222.2\n 264.4   263.0   265.85  263.6   265.35  257.25  254.2   258.5   261.6   259.95  259.45  262.3   262.65  259.25     219.0   217.95  218.6   223.2   220.75  215.1   215.2   218.25  216.35    0.0   215.75  216.8   220.15\n 258.75  262.2   264.2   262.55  262.4   262.6   259.05  258.65  257.5   259.4   265.45  260.1   260.2   261.6      217.4   220.85  219.15  218.05  214.5   214.15  215.8   224.5   217.2   217.35    0.0   218.75  222.8\n 264.5   263.35  257.0   262.9   258.65  264.95  266.05  260.75  259.15  264.8   263.95  265.5   267.3   265.35     221.95  222.65  224.25  221.05  220.95  216.5   220.25  220.5   217.2   218.5   218.05    0.0   223.1\n 266.6   266.35  262.65  262.2   264.45  267.2   266.8   264.25  263.75  262.75  264.5   266.55  267.4   271.6      223.9   226.0   225.6   228.65  225.3   219.85  218.25  220.55  220.75  217.1   220.2   225.15    0.0","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"Of course, it is easier to make sense of the result if we visualize it. Here, we use Plots.jl's heatmap function.","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"using Plots\nheatmap(latencies; c = :viridis, frame=:box)","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"(Image: core2core.png)","category":"page"},{"location":"examples/ex_core2core_latency/","page":"Core-to-Core Latency","title":"Core-to-Core Latency","text":"The two sockets / CPUs of the system with 20 cores each are clearly visible since the inter-core latency of cores on different sockets is, expectedly, higher than the same for cores sitting on the same socket / in the same CPU. Note that due to fluctuations in our imperfect benchmark the result is not precisely symmetric (which, of course, it should be in theory).","category":"page"}]
}
